{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97aa1631-bdf1-446f-8a7a-12eb0de74245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-26 22:23:57,158 INFO test.py line 41 64292] => Loading config ...\n",
      "[2024-08-26 22:23:57,159 INFO test.py line 48 64292] => Building model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj_head shape says Linear(in_features=64, out_features=512, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-26 22:23:59,919 INFO test.py line 61 64292] Num params: 97447088\n",
      "[2024-08-26 22:24:00,123 INFO test.py line 68 64292] Loading weight at: ../../models/PointTransformerV3/scannet-semseg-pt-v3m1-1-ppt-extreme/model/model_best.pth\n",
      "[2024-08-26 22:24:00,744 INFO test.py line 84 64292] => Loaded weight '../../models/PointTransformerV3/scannet-semseg-pt-v3m1-1-ppt-extreme/model/model_best.pth' (epoch 94)\n",
      "[2024-08-26 22:24:00,748 INFO test.py line 53 64292] => Building test dataset & dataloader ...\n",
      "[2024-08-26 22:24:00,750 INFO scannet.py line 72 64292] Totally 0 x 1 samples in val set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DITCHING CLASS EMBEDDING\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "import graphviz\n",
    "graphviz.set_jupyter_format('svg')\n",
    "from lora_pytorch import LoRA\n",
    "assert torch.cuda.is_available()\n",
    "from torchview import draw_graph\n",
    "from torchviz import make_dot\n",
    "from graphviz import Digraph\n",
    "\n",
    "from pointcept.engines.defaults import (\n",
    "    default_argument_parser,\n",
    "    default_config_parser,\n",
    "    default_setup,\n",
    ")\n",
    "from pointcept.engines.test import TESTERS\n",
    "from pointcept.engines.launch import launch\n",
    "from pointcept.engines.test import TesterBase, SemSegTester\n",
    "\n",
    "repo_root = Path(\"../..\")\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def create_spoofed_input(batch_size=2, num_points=1000, n_classes=5, num_features=6, device='cpu'):\n",
    "    return {\n",
    "        'coord': torch.rand(num_points * batch_size, num_features, device=device),\n",
    "        'feat': torch.rand(num_points * batch_size, num_features, device=device),\n",
    "        'grid_coord': torch.randint(0, 100, (num_points * batch_size, 3), device=device),\n",
    "        'batch': torch.arange(batch_size, device=device).repeat_interleave(num_points),\n",
    "        'offset': torch.tensor([num_points * i for i in range(1, batch_size + 1)], device=device),\n",
    "        'condition': ['ScanNet'] * batch_size,\n",
    "        'grid_size': torch.tensor([0.01], device=device),\n",
    "        'segment': torch.randint(low=0, high=n_classes-1, size=(num_points * batch_size,), device=device)\n",
    "    }\n",
    "\n",
    "\n",
    "def patch_cfg(cfg: dict, repo_root: Path = repo_root) -> dict:\n",
    "    cfg = cfg.copy()\n",
    "    cfg[\"my_data_root\"] = repo_root / cfg[\"my_data_root\"]\n",
    "    cfg[\"weight\"] = repo_root / cfg[\"weight\"]\n",
    "    cfg[\"batch_size_test_per_gpu\"] = 1\n",
    "    return cfg\n",
    "\n",
    "\n",
    "repo_root = Path(\"../..\")\n",
    "cfg_file = Path(\"../../test/custom-ppt-config.py\"); assert cfg_file.exists\n",
    "device = \"cuda\"\n",
    "\n",
    "args = default_argument_parser().parse_args(args=[\"--config-file\", f\"{cfg_file}\"])\n",
    "cfg = default_config_parser(args.config_file, args.options); cfg = patch_cfg(cfg)\n",
    "\n",
    "tester = TESTERS.build(dict(type=cfg.test.type, cfg=cfg))\n",
    "model = tester.model\n",
    "model.to(device)\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4c725-2926-43b7-aed2-9f348530cc91",
   "metadata": {},
   "source": [
    "# Visualise netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f17df69-85bb-4481-9c82-d4b36bd058b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece78c4e-df11-4a38-9175-75309a337b1b",
   "metadata": {},
   "source": [
    "Now install netron and open this file:\n",
    "\n",
    "```bash\n",
    "snap install netron\n",
    "snap run netron\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92870c6-b661-422a-8542-a3b7f0e4bac7",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301b9e8-b406-44e0-9e8e-0ed4f5a8ba81",
   "metadata": {},
   "source": [
    "Compare implementations, need to understand wtf is going on in lora-pytorch with the custom MHA implementation and why this isn't necessary in the pytora + claude-generated solutions\n",
    "\n",
    "maybe need to compare param counts and see the difference in their behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac3631-feea-49f9-9dc2-d8ac19297e51",
   "metadata": {},
   "source": [
    "### lora-pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf019940-a66c-402d-ae71-f164b94cf3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bare model:  110759388\n",
      "lora: 13312300\n"
     ]
    }
   ],
   "source": [
    "lora_model = LoRA.from_module(model, rank=50)\n",
    "print(\"bare model: \", count_trainable_parameters(model))\n",
    "print(\"lora:\", count_trainable_parameters(lora_model))\n",
    "torch.save(model, \"model_lora.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76140c1e-d0ec-4dbf-bb16-2f62dc4fc47c",
   "metadata": {},
   "source": [
    "### pytora implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe6fbb5-2525-4ba2-8bd5-eaaed1102c1c",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf183b0f-3960-4586-ace2-567cb7365ded",
   "metadata": {},
   "source": [
    "### minlora implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0772a9-0b33-40be-a432-b997c9e34f33",
   "metadata": {},
   "source": [
    "#### simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "249031c8-7288-4f6a-ade9-1c0c76ad785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA applied to blocks.0.attention.out_proj: False\n",
      "LoRA applied to blocks.0.ffn.0: True\n",
      "LoRA applied to blocks.0.ffn.2: True\n",
      "LoRA applied to blocks.0.conv: True\n",
      "LoRA applied to blocks.1.attention.out_proj: False\n",
      "LoRA applied to blocks.1.ffn.0: True\n",
      "LoRA applied to blocks.1.ffn.2: True\n",
      "LoRA applied to blocks.1.conv: True\n",
      "LoRA applied to blocks.2.attention.out_proj: False\n",
      "LoRA applied to blocks.2.ffn.0: True\n",
      "LoRA applied to blocks.2.ffn.2: True\n",
      "LoRA applied to blocks.2.conv: True\n",
      "LoRA applied to final_layer: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from minlora import add_lora, LoRAParametrization\n",
    "\n",
    "# Example custom architecture\n",
    "class CustomBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(dim, 8)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, 4*dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*dim, dim)\n",
    "        )\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.attention(x, x, x)[0] + x\n",
    "        x = self.ffn(x) + x\n",
    "        x = x.permute(0, 2, 1).unsqueeze(-1)  # reshape for 2D conv\n",
    "        x = self.conv(x).squeeze(-1).permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, dim, num_blocks):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([CustomBlock(dim) for _ in range(num_blocks)])\n",
    "        self.final_layer = nn.Linear(dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return self.final_layer(x)\n",
    "\n",
    "# Custom LoRA configuration\n",
    "custom_lora_config = {\n",
    "    nn.Linear: {\n",
    "        \"weight\": LoRAParametrization.from_linear\n",
    "    },\n",
    "    # nn.MultiheadAttention: {\n",
    "    #     \"out_proj.weight\": LoRAParametrization.from_linear\n",
    "    # },\n",
    "    nn.Conv2d: {\n",
    "        \"weight\": LoRAParametrization.from_conv2d\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create and apply LoRA\n",
    "model = CustomModel(dim=256, num_blocks=3)\n",
    "add_lora(model, lora_config=custom_lora_config)\n",
    "\n",
    "# Verify LoRA application\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)) or (isinstance(module, nn.MultiheadAttention) and 'weight' in name):\n",
    "        print(f\"LoRA applied to {name}: {hasattr(module, 'parametrizations')}\")\n",
    "\n",
    "# # Training loop (pseudo-code)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = criterion(model(batch), targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317bc98-49b3-45eb-b9f7-7881112a0ae3",
   "metadata": {},
   "source": [
    "#### for PPT+PTvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b67844-b7be-4072-be00-36475b883e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import minlora\n",
    "from minlora import (\n",
    "    LoRAParametrization,\n",
    "    add_lora,\n",
    "    merge_lora,\n",
    "    remove_lora\n",
    ")\n",
    "from minlora.model import add_lora_by_name, apply_lora\n",
    "\n",
    "\n",
    "from spconv.pytorch.conv import SubMConv3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de76c6f-c89a-4b42-a06d-02e77372fa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before LoRA: 97447088\n",
      "after LoRA: 532492\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27230259-4488-4bb1-a727-34fe57fab909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before LoRA: 97447088\n",
      "after LoRA: 1325956\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "def configure_optimizers_lora(self, weight_decay, learning_rate, betas, device_type):\n",
    "    # we apply weight decay to all lora params\n",
    "    optim_groups = [\n",
    "        # note: .get_lora_params() returns a generator\n",
    "        # we need to wrap it in a list so we can consume it twice\n",
    "        {\"params\": list(minlora.get_lora_params(self)) , \"weight_decay\": weight_decay},\n",
    "        # you can also add biases for fine-tuning,\n",
    "        # but I want to make sure lora alone works\n",
    "        # {\"params\": minlora.get_bias_params(self), \"weight_decay\": 0.0}, # bias params don't get weight decay\n",
    "    ]\n",
    "\n",
    "    def parameter_count(optim_groups):\n",
    "        n = sum(p.numel() for group in optim_groups for p in group[\"params\"])\n",
    "        if n < 1e6:\n",
    "            return f\"{n/1e3:.1f}k\"\n",
    "        else:\n",
    "            return f\"{n/1e6:.1f}M\"\n",
    "\n",
    "    print(f\"optimizing {parameter_count(optim_groups)} parameters\")\n",
    "\n",
    "    # new PyTorch nightly has a new 'fused' option for AdamW that is much faster\n",
    "    use_fused = (device_type == \"cuda\") and (\"fused\" in inspect.signature(torch.optim.AdamW).parameters)\n",
    "    print(f\"using fused AdamW: {use_fused}\")\n",
    "    extra_args = dict(fused=True) if use_fused else dict()\n",
    "    optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "lora_dropout_p = 0.0\n",
    "rank=4\n",
    "lora_alpha = 64\n",
    "lora_config = {\n",
    "    torch.nn.Embedding: {\n",
    "        \"weight\": partial(LoRAParametrization.from_embedding, rank=rank, lora_alpha=lora_alpha),\n",
    "    },\n",
    "    torch.nn.Linear: {\n",
    "        \"weight\": partial(LoRAParametrization.from_linear, rank=rank, lora_alpha=lora_alpha),\n",
    "    },\n",
    "    SubMConv3d: {\n",
    "        \"weight\": partial(LoRAParametrization.from_sparseconv3d, rank=rank, lora_alpha=lora_alpha),\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"before LoRA:\", count_trainable_parameters(model))\n",
    "\n",
    "def freeze_non_lora_params(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if True:#'lora' not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "freeze_non_lora_params(model)\n",
    "\n",
    "minlora.add_lora(model, lora_config=lora_config)\n",
    "print(\"after LoRA:\", count_trainable_parameters(model))\n",
    "# if use_lora:\n",
    "#     optimizer = configure_optimizers_lora(model, weight_decay, learning_rate, (beta1, beta2), device_type)\n",
    "# else:\n",
    "#     optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)\n",
    "# if init_from == 'resume':\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7004cf3-0a9f-4b45-b92a-d8d5725d5f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_spoofed_input(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be3af30-b71e-406f-932b-2bcc52f3b746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])=\n",
      "feat.shape=torch.Size([2000, 512])\n",
      "self.class_embedding.shape=torch.Size([13, 512])\n",
      "sim.shape=torch.Size([2000, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(4.4570, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e630680-ff3d-49f6-834a-20f965b5a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': PointPromptTraining(\n",
       "   (backbone): PointTransformerV3(\n",
       "     (embedding): Embedding(\n",
       "       (stem): PointSequential(\n",
       "         (conv): ParametrizedSubMConv3d(\n",
       "           6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (enc): PointSequential(\n",
       "       (enc0): PointSequential(\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=48, out_features=144, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=48, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=192, out_features=48, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): Identity()\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=48, out_features=144, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=48, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=192, out_features=48, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.018)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=48, out_features=144, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=48, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=192, out_features=48, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.035)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc1): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.053)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.071)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.088)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc2): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.106)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.124)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.141)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc3): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.159)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.176)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.194)\n",
       "           )\n",
       "         )\n",
       "         (block3): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.212)\n",
       "           )\n",
       "         )\n",
       "         (block4): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.229)\n",
       "           )\n",
       "         )\n",
       "         (block5): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.247)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc4): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=512, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=512, out_features=2048, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=2048, out_features=512, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.265)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=512, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=512, out_features=2048, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=2048, out_features=512, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.282)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=512, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=512, out_features=2048, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=2048, out_features=512, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.300)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec): PointSequential(\n",
       "       (dec3): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=512, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.300)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.273)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.245)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (dec2): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=384, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.218)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.191)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.164)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (dec1): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=192, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.136)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.109)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.082)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (dec0): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=96, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=48, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=64, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=64, out_features=256, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=256, out_features=64, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.055)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=64, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=64, out_features=256, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=256, out_features=64, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.027)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): ParametrizedSubMConv3d(\n",
       "               64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=64, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=64, out_features=256, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=256, out_features=64, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): Identity()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (embedding_table): ParametrizedEmbedding(\n",
       "     3, 256\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_head): ParametrizedLinear(\n",
       "     in_features=64, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone': PointTransformerV3(\n",
       "   (embedding): Embedding(\n",
       "     (stem): PointSequential(\n",
       "       (conv): ParametrizedSubMConv3d(\n",
       "         6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (enc): PointSequential(\n",
       "     (enc0): PointSequential(\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=48, out_features=144, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=48, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=192, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): Identity()\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=48, out_features=144, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=48, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=192, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.018)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=48, out_features=144, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=48, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=192, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.035)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc1): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.053)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.071)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.088)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc2): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.106)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.124)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.141)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc3): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.159)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.176)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.194)\n",
       "         )\n",
       "       )\n",
       "       (block3): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.212)\n",
       "         )\n",
       "       )\n",
       "       (block4): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.229)\n",
       "         )\n",
       "       )\n",
       "       (block5): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.247)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc4): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=512, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=512, out_features=2048, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=2048, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.265)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=512, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=512, out_features=2048, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=2048, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.282)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=512, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=512, out_features=2048, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=2048, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dec): PointSequential(\n",
       "     (dec3): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=512, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.273)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.245)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec2): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=384, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.218)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.191)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.164)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec1): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=192, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.136)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.109)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.082)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec0): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=96, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=48, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=64, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=64, out_features=256, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=256, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.055)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=64, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=64, out_features=256, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=256, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.027)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): ParametrizedSubMConv3d(\n",
       "             64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=64, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=64, out_features=256, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=256, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): Identity()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding': Embedding(\n",
       "   (stem): PointSequential(\n",
       "     (conv): ParametrizedSubMConv3d(\n",
       "       6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding.stem': PointSequential(\n",
       "   (conv): ParametrizedSubMConv3d(\n",
       "     6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.embedding.stem.conv': ParametrizedSubMConv3d(\n",
       "   6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding.stem.conv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding.stem.conv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.embedding.stem.conv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.embedding.stem.norm': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding.stem.norm.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.embedding.stem.norm.norm.0': BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.embedding.stem.norm.norm.1': BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.embedding.stem.norm.norm.2': BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.embedding.stem.act': GELU(approximate='none'),\n",
       " 'backbone.enc': PointSequential(\n",
       "   (enc0): PointSequential(\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=48, out_features=144, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=48, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=192, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): Identity()\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=48, out_features=144, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=48, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=192, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.018)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=48, out_features=144, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=48, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=192, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.035)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc1): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.053)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.071)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.088)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc2): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.106)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.124)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.141)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc3): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.159)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.176)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.194)\n",
       "       )\n",
       "     )\n",
       "     (block3): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.212)\n",
       "       )\n",
       "     )\n",
       "     (block4): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.229)\n",
       "       )\n",
       "     )\n",
       "     (block5): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.247)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc4): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=512, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=512, out_features=2048, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=2048, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.265)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=512, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=512, out_features=2048, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=2048, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.282)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): ParametrizedSubMConv3d(\n",
       "           512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=512, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=512, out_features=2048, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=2048, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.300)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0': PointSequential(\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=48, out_features=144, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=48, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=192, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): Identity()\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=48, out_features=144, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=48, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=192, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.018)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=48, out_features=144, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=48, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=192, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.035)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=48, out_features=144, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=48, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=192, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): Identity()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.0': ParametrizedSubMConv3d(\n",
       "   48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=48, out_features=144, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=48, out_features=144, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc0.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=48, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=192, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=48, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=192, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=48, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=192, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block0.drop_path': PointSequential(\n",
       "   (0): Identity()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.drop_path.0': Identity(),\n",
       " 'backbone.enc.enc0.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=48, out_features=144, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=48, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=192, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.018)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.0': ParametrizedSubMConv3d(\n",
       "   48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=48, out_features=144, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=48, out_features=144, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc0.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=48, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=192, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=48, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=192, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=48, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=192, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.018)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.drop_path.0': DropPath(drop_prob=0.018),\n",
       " 'backbone.enc.enc0.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=48, out_features=144, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=48, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=192, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.035)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.0': ParametrizedSubMConv3d(\n",
       "   48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=48, out_features=144, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=48, out_features=144, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc0.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=48, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=192, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=48, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=192, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=48, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=192, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.035)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.drop_path.0': DropPath(drop_prob=0.035),\n",
       " 'backbone.enc.enc1': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=96, out_features=288, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=96, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=384, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.053)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=96, out_features=288, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=96, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=384, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.071)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=96, out_features=288, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=96, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=384, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.088)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.down.norm.0.norm.0': BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc1.down.norm.0.norm.1': BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc1.down.norm.0.norm.2': BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc1.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc1.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=96, out_features=288, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=96, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=384, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.053)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.0': ParametrizedSubMConv3d(\n",
       "   96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=96, out_features=288, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=96, out_features=288, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc1.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=96, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=384, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=96, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=384, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=96, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=384, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.053)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.drop_path.0': DropPath(drop_prob=0.053),\n",
       " 'backbone.enc.enc1.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=96, out_features=288, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=96, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=384, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.071)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.0': ParametrizedSubMConv3d(\n",
       "   96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=96, out_features=288, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=96, out_features=288, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc1.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=96, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=384, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=96, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=384, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=96, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=384, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.071)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.drop_path.0': DropPath(drop_prob=0.071),\n",
       " 'backbone.enc.enc1.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=96, out_features=288, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=96, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=384, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.088)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.0': ParametrizedSubMConv3d(\n",
       "   96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=96, out_features=288, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=96, out_features=288, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc1.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=96, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=384, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=96, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=384, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=96, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=384, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.088)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.drop_path.0': DropPath(drop_prob=0.088),\n",
       " 'backbone.enc.enc2': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=192, out_features=576, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=192, out_features=768, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=768, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.106)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=192, out_features=576, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=192, out_features=768, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=768, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.124)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=192, out_features=576, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=192, out_features=768, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=768, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.141)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.down.norm.0.norm.0': BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc2.down.norm.0.norm.1': BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc2.down.norm.0.norm.2': BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc2.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc2.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=192, out_features=576, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=192, out_features=768, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=768, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.106)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.0': ParametrizedSubMConv3d(\n",
       "   192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=192, out_features=576, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=192, out_features=576, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc2.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=192, out_features=768, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=768, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=192, out_features=768, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=768, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=192, out_features=768, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=768, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.106)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.drop_path.0': DropPath(drop_prob=0.106),\n",
       " 'backbone.enc.enc2.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=192, out_features=576, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=192, out_features=768, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=768, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.124)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.0': ParametrizedSubMConv3d(\n",
       "   192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=192, out_features=576, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=192, out_features=576, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc2.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=192, out_features=768, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=768, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=192, out_features=768, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=768, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=192, out_features=768, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=768, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.124)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.drop_path.0': DropPath(drop_prob=0.124),\n",
       " 'backbone.enc.enc2.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=192, out_features=576, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=192, out_features=768, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=768, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.141)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.0': ParametrizedSubMConv3d(\n",
       "   192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=192, out_features=576, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=192, out_features=576, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc2.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=192, out_features=768, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=768, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=192, out_features=768, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=768, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=192, out_features=768, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=768, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.141)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.drop_path.0': DropPath(drop_prob=0.141),\n",
       " 'backbone.enc.enc3': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.159)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.176)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.194)\n",
       "     )\n",
       "   )\n",
       "   (block3): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.212)\n",
       "     )\n",
       "   )\n",
       "   (block4): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.229)\n",
       "     )\n",
       "   )\n",
       "   (block5): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.247)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.down.norm.0.norm.0': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc3.down.norm.0.norm.1': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc3.down.norm.0.norm.2': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc3.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc3.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.159)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.0': ParametrizedSubMConv3d(\n",
       "   384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.159)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.drop_path.0': DropPath(drop_prob=0.159),\n",
       " 'backbone.enc.enc3.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.176)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.0': ParametrizedSubMConv3d(\n",
       "   384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.176)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.drop_path.0': DropPath(drop_prob=0.176),\n",
       " 'backbone.enc.enc3.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.194)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.0': ParametrizedSubMConv3d(\n",
       "   384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.194)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.drop_path.0': DropPath(drop_prob=0.194),\n",
       " 'backbone.enc.enc3.block3': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.212)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.0': ParametrizedSubMConv3d(\n",
       "   384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block3.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block3.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block3.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.212)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.drop_path.0': DropPath(drop_prob=0.212),\n",
       " 'backbone.enc.enc3.block4': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.229)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.0': ParametrizedSubMConv3d(\n",
       "   384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block4.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block4.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block4.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.229)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.drop_path.0': DropPath(drop_prob=0.229),\n",
       " 'backbone.enc.enc3.block5': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.247)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.0': ParametrizedSubMConv3d(\n",
       "   384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block5.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block5.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block5.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.247)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.drop_path.0': DropPath(drop_prob=0.247),\n",
       " 'backbone.enc.enc4': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=512, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=512, out_features=2048, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=2048, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.265)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=512, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=512, out_features=2048, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=2048, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.282)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): ParametrizedSubMConv3d(\n",
       "         512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=512, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=512, out_features=2048, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=2048, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.300)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.down.norm.0.norm.0': BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc4.down.norm.0.norm.1': BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc4.down.norm.0.norm.2': BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc4.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc4.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc4.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=512, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=512, out_features=2048, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=2048, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.265)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.0': ParametrizedSubMConv3d(\n",
       "   512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=512, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=512, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc4.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=512, out_features=2048, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=2048, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=512, out_features=2048, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=2048, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=512, out_features=2048, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=2048, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.265)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.drop_path.0': DropPath(drop_prob=0.265),\n",
       " 'backbone.enc.enc4.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=512, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=512, out_features=2048, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=2048, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.282)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.0': ParametrizedSubMConv3d(\n",
       "   512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=512, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=512, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc4.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=512, out_features=2048, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=2048, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=512, out_features=2048, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=2048, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=512, out_features=2048, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=2048, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.282)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.drop_path.0': DropPath(drop_prob=0.282),\n",
       " 'backbone.enc.enc4.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): ParametrizedSubMConv3d(\n",
       "       512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=512, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=512, out_features=2048, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=2048, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.300)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe': PointSequential(\n",
       "   (0): ParametrizedSubMConv3d(\n",
       "     512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.0': ParametrizedSubMConv3d(\n",
       "   512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=512, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=512, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc4.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=512, out_features=2048, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=2048, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=512, out_features=2048, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=2048, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=512, out_features=2048, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ab0ce3-0646-49af-b8a0-a3230d4bbc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': PointPromptTraining(\n",
       "   (backbone): PointTransformerV3(\n",
       "     (embedding): Embedding(\n",
       "       (stem): PointSequential(\n",
       "         (conv): SubMConv3d(6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native)\n",
       "         (norm): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (enc): PointSequential(\n",
       "       (enc0): PointSequential(\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=48, out_features=144, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=48, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=192, out_features=48, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): Identity()\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=48, out_features=144, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=48, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=192, out_features=48, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.018)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=48, out_features=144, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=48, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=48, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=192, out_features=48, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.035)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc1): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.053)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.071)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.088)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc2): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.106)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.124)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.141)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc3): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.159)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.176)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.194)\n",
       "           )\n",
       "         )\n",
       "         (block3): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.212)\n",
       "           )\n",
       "         )\n",
       "         (block4): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.229)\n",
       "           )\n",
       "         )\n",
       "         (block5): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.247)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (enc4): PointSequential(\n",
       "         (down): SerializedPooling(\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): PointSequential(\n",
       "             (0): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=512, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=512, out_features=2048, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=2048, out_features=512, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.265)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=512, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=512, out_features=2048, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=2048, out_features=512, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.282)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=512, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=512, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=512, out_features=2048, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=2048, out_features=512, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.300)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec): PointSequential(\n",
       "       (dec3): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=512, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.300)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.273)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=384, out_features=1152, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=384, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=384, out_features=1536, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=1536, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.245)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (dec2): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=384, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.218)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.191)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=192, out_features=576, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=192, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=192, out_features=768, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=768, out_features=192, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.164)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (dec1): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=192, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.136)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.109)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=96, out_features=288, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=96, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=96, out_features=384, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=384, out_features=96, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.082)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (dec0): PointSequential(\n",
       "         (up): SerializedUnpooling(\n",
       "           (proj): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=96, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "           (proj_skip): PointSequential(\n",
       "             (0): ParametrizedLinear(\n",
       "               in_features=48, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (1): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "               )\n",
       "             )\n",
       "             (2): GELU(approximate='none')\n",
       "           )\n",
       "         )\n",
       "         (block0): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=64, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=64, out_features=256, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=256, out_features=64, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.055)\n",
       "           )\n",
       "         )\n",
       "         (block1): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=64, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=64, out_features=256, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=256, out_features=64, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): DropPath(drop_prob=0.027)\n",
       "           )\n",
       "         )\n",
       "         (block2): Block(\n",
       "           (cpe): PointSequential(\n",
       "             (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "             (1): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (2): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (norm1): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (attn): SerializedAttention(\n",
       "             (qkv): ParametrizedLinear(\n",
       "               in_features=64, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj): ParametrizedLinear(\n",
       "               in_features=64, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "             (softmax): Softmax(dim=-1)\n",
       "           )\n",
       "           (norm2): PointSequential(\n",
       "             (0): PDNorm(\n",
       "               (norm): ModuleList(\n",
       "                 (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (mlp): PointSequential(\n",
       "             (0): MLP(\n",
       "               (fc1): ParametrizedLinear(\n",
       "                 in_features=64, out_features=256, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (act): GELU(approximate='none')\n",
       "               (fc2): ParametrizedLinear(\n",
       "                 in_features=256, out_features=64, bias=True\n",
       "                 (parametrizations): ModuleDict(\n",
       "                   (weight): ParametrizationList(\n",
       "                     (0): LoRAParametrization()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "               (drop): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): PointSequential(\n",
       "             (0): Identity()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (embedding_table): ParametrizedEmbedding(\n",
       "     3, 256\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_head): ParametrizedLinear(\n",
       "     in_features=64, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone': PointTransformerV3(\n",
       "   (embedding): Embedding(\n",
       "     (stem): PointSequential(\n",
       "       (conv): SubMConv3d(6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native)\n",
       "       (norm): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (enc): PointSequential(\n",
       "     (enc0): PointSequential(\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=48, out_features=144, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=48, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=192, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): Identity()\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=48, out_features=144, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=48, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=192, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.018)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=48, out_features=144, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=48, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=48, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=192, out_features=48, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.035)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc1): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.053)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.071)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.088)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc2): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.106)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.124)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.141)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc3): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.159)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.176)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.194)\n",
       "         )\n",
       "       )\n",
       "       (block3): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.212)\n",
       "         )\n",
       "       )\n",
       "       (block4): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.229)\n",
       "         )\n",
       "       )\n",
       "       (block5): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.247)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (enc4): PointSequential(\n",
       "       (down): SerializedPooling(\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): PointSequential(\n",
       "           (0): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=512, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=512, out_features=2048, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=2048, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.265)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=512, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=512, out_features=2048, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=2048, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.282)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=512, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=512, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=512, out_features=2048, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=2048, out_features=512, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dec): PointSequential(\n",
       "     (dec3): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=512, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.273)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=384, out_features=1152, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=384, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=384, out_features=1536, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=1536, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.245)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec2): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=384, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.218)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.191)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=192, out_features=576, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=192, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=192, out_features=768, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=768, out_features=192, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.164)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec1): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=192, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.136)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.109)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=96, out_features=288, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=96, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=96, out_features=384, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=384, out_features=96, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.082)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (dec0): PointSequential(\n",
       "       (up): SerializedUnpooling(\n",
       "         (proj): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=96, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "         (proj_skip): PointSequential(\n",
       "           (0): ParametrizedLinear(\n",
       "             in_features=48, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (1): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "             )\n",
       "           )\n",
       "           (2): GELU(approximate='none')\n",
       "         )\n",
       "       )\n",
       "       (block0): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=64, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=64, out_features=256, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=256, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.055)\n",
       "         )\n",
       "       )\n",
       "       (block1): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=64, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=64, out_features=256, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=256, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): DropPath(drop_prob=0.027)\n",
       "         )\n",
       "       )\n",
       "       (block2): Block(\n",
       "         (cpe): PointSequential(\n",
       "           (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "           (1): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (2): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (norm1): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (attn): SerializedAttention(\n",
       "           (qkv): ParametrizedLinear(\n",
       "             in_features=64, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj): ParametrizedLinear(\n",
       "             in_features=64, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "           (softmax): Softmax(dim=-1)\n",
       "         )\n",
       "         (norm2): PointSequential(\n",
       "           (0): PDNorm(\n",
       "             (norm): ModuleList(\n",
       "               (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (mlp): PointSequential(\n",
       "           (0): MLP(\n",
       "             (fc1): ParametrizedLinear(\n",
       "               in_features=64, out_features=256, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (act): GELU(approximate='none')\n",
       "             (fc2): ParametrizedLinear(\n",
       "               in_features=256, out_features=64, bias=True\n",
       "               (parametrizations): ModuleDict(\n",
       "                 (weight): ParametrizationList(\n",
       "                   (0): LoRAParametrization()\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "             (drop): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): PointSequential(\n",
       "           (0): Identity()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding': Embedding(\n",
       "   (stem): PointSequential(\n",
       "     (conv): SubMConv3d(6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native)\n",
       "     (norm): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding.stem': PointSequential(\n",
       "   (conv): SubMConv3d(6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native)\n",
       "   (norm): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.embedding.stem.conv': SubMConv3d(6, 48, kernel_size=[5, 5, 5], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.Native),\n",
       " 'backbone.embedding.stem.norm': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.embedding.stem.norm.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.embedding.stem.norm.norm.0': BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.embedding.stem.norm.norm.1': BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.embedding.stem.norm.norm.2': BatchNorm1d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.embedding.stem.act': GELU(approximate='none'),\n",
       " 'backbone.enc': PointSequential(\n",
       "   (enc0): PointSequential(\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=48, out_features=144, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=48, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=192, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): Identity()\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=48, out_features=144, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=48, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=192, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.018)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=48, out_features=144, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=48, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=48, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=192, out_features=48, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.035)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc1): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.053)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.071)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.088)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc2): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.106)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.124)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.141)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc3): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.159)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.176)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.194)\n",
       "       )\n",
       "     )\n",
       "     (block3): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.212)\n",
       "       )\n",
       "     )\n",
       "     (block4): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.229)\n",
       "       )\n",
       "     )\n",
       "     (block5): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.247)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (enc4): PointSequential(\n",
       "     (down): SerializedPooling(\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): PointSequential(\n",
       "         (0): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=512, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=512, out_features=2048, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=2048, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.265)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=512, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=512, out_features=2048, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=2048, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.282)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=512, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=512, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=512, out_features=2048, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=2048, out_features=512, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.300)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0': PointSequential(\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=48, out_features=144, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=48, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=192, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): Identity()\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=48, out_features=144, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=48, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=192, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.018)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=48, out_features=144, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=48, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=48, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=192, out_features=48, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.035)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=48, out_features=144, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=48, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=192, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): Identity()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe': PointSequential(\n",
       "   (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.0': SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc0.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.cpe.2.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm1.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=48, out_features=144, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=48, out_features=144, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc0.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.norm2.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=48, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=192, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=48, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=192, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=48, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=192, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block0.drop_path': PointSequential(\n",
       "   (0): Identity()\n",
       " ),\n",
       " 'backbone.enc.enc0.block0.drop_path.0': Identity(),\n",
       " 'backbone.enc.enc0.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=48, out_features=144, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=48, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=192, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.018)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe': PointSequential(\n",
       "   (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.0': SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc0.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.cpe.2.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm1.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=48, out_features=144, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=48, out_features=144, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc0.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.norm2.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=48, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=192, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=48, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=192, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=48, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=192, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.018)\n",
       " ),\n",
       " 'backbone.enc.enc0.block1.drop_path.0': DropPath(drop_prob=0.018),\n",
       " 'backbone.enc.enc0.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=48, out_features=144, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=48, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=192, out_features=48, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.035)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe': PointSequential(\n",
       "   (0): SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.0': SubMConv3d(48, 48, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc0.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.cpe.2.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm1.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=48, out_features=144, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=48, out_features=144, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc0.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((48,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm.0': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm.1': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.norm2.0.norm.2': LayerNorm((48,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc0.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=48, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=192, out_features=48, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=48, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=192, out_features=48, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=48, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=192, out_features=48, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc0.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc0.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.035)\n",
       " ),\n",
       " 'backbone.enc.enc0.block2.drop_path.0': DropPath(drop_prob=0.035),\n",
       " 'backbone.enc.enc1': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=48, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=96, out_features=288, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=96, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=384, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.053)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=96, out_features=288, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=96, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=384, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.071)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=96, out_features=288, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=96, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=96, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=384, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.088)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=48, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj': ParametrizedLinear(\n",
       "   in_features=48, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.down.norm.0.norm.0': BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc1.down.norm.0.norm.1': BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc1.down.norm.0.norm.2': BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc1.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc1.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=96, out_features=288, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=96, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=384, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.053)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe': PointSequential(\n",
       "   (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.0': SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc1.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.cpe.2.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm1.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=96, out_features=288, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=96, out_features=288, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc1.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.norm2.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=96, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=384, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=96, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=384, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=96, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=384, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.053)\n",
       " ),\n",
       " 'backbone.enc.enc1.block0.drop_path.0': DropPath(drop_prob=0.053),\n",
       " 'backbone.enc.enc1.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=96, out_features=288, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=96, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=384, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.071)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe': PointSequential(\n",
       "   (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.0': SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc1.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.cpe.2.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm1.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=96, out_features=288, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=96, out_features=288, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc1.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.norm2.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=96, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=384, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=96, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=384, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=96, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=384, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.071)\n",
       " ),\n",
       " 'backbone.enc.enc1.block1.drop_path.0': DropPath(drop_prob=0.071),\n",
       " 'backbone.enc.enc1.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=96, out_features=288, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=96, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=384, out_features=96, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.088)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe': PointSequential(\n",
       "   (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.0': SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc1.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.cpe.2.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm1.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=96, out_features=288, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=96, out_features=288, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc1.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm.0': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm.1': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.norm2.0.norm.2': LayerNorm((96,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc1.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=96, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=384, out_features=96, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=96, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=384, out_features=96, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=96, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=384, out_features=96, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc1.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc1.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.088)\n",
       " ),\n",
       " 'backbone.enc.enc1.block2.drop_path.0': DropPath(drop_prob=0.088),\n",
       " 'backbone.enc.enc2': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=96, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=192, out_features=576, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=192, out_features=768, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=768, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.106)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=192, out_features=576, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=192, out_features=768, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=768, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.124)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=192, out_features=576, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=192, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=192, out_features=768, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=768, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.141)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=96, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj': ParametrizedLinear(\n",
       "   in_features=96, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.down.norm.0.norm.0': BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc2.down.norm.0.norm.1': BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc2.down.norm.0.norm.2': BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc2.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc2.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=192, out_features=576, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=192, out_features=768, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=768, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.106)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe': PointSequential(\n",
       "   (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.0': SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc2.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.cpe.2.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm1.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=192, out_features=576, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=192, out_features=576, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc2.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.norm2.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=192, out_features=768, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=768, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=192, out_features=768, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=768, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=192, out_features=768, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=768, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.106)\n",
       " ),\n",
       " 'backbone.enc.enc2.block0.drop_path.0': DropPath(drop_prob=0.106),\n",
       " 'backbone.enc.enc2.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=192, out_features=576, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=192, out_features=768, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=768, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.124)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe': PointSequential(\n",
       "   (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.0': SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc2.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.cpe.2.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm1.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=192, out_features=576, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=192, out_features=576, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc2.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.norm2.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=192, out_features=768, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=768, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=192, out_features=768, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=768, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=192, out_features=768, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=768, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.124)\n",
       " ),\n",
       " 'backbone.enc.enc2.block1.drop_path.0': DropPath(drop_prob=0.124),\n",
       " 'backbone.enc.enc2.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=192, out_features=576, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=192, out_features=768, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=768, out_features=192, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.141)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe': PointSequential(\n",
       "   (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.0': SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc2.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.cpe.2.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm1.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=192, out_features=576, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=192, out_features=576, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc2.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm.0': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm.1': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.norm2.0.norm.2': LayerNorm((192,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc2.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=192, out_features=768, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=768, out_features=192, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=192, out_features=768, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=768, out_features=192, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=192, out_features=768, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=768, out_features=192, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc2.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc2.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.141)\n",
       " ),\n",
       " 'backbone.enc.enc2.block2.drop_path.0': DropPath(drop_prob=0.141),\n",
       " 'backbone.enc.enc3': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=192, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.159)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.176)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.194)\n",
       "     )\n",
       "   )\n",
       "   (block3): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.212)\n",
       "     )\n",
       "   )\n",
       "   (block4): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.229)\n",
       "     )\n",
       "   )\n",
       "   (block5): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.247)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=192, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj': ParametrizedLinear(\n",
       "   in_features=192, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.down.norm.0.norm.0': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc3.down.norm.0.norm.1': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc3.down.norm.0.norm.2': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc3.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc3.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.159)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe': PointSequential(\n",
       "   (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.0': SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc3.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.159)\n",
       " ),\n",
       " 'backbone.enc.enc3.block0.drop_path.0': DropPath(drop_prob=0.159),\n",
       " 'backbone.enc.enc3.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.176)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe': PointSequential(\n",
       "   (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.0': SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc3.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.176)\n",
       " ),\n",
       " 'backbone.enc.enc3.block1.drop_path.0': DropPath(drop_prob=0.176),\n",
       " 'backbone.enc.enc3.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.194)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe': PointSequential(\n",
       "   (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.0': SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc3.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.194)\n",
       " ),\n",
       " 'backbone.enc.enc3.block2.drop_path.0': DropPath(drop_prob=0.194),\n",
       " 'backbone.enc.enc3.block3': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.212)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe': PointSequential(\n",
       "   (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.0': SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc3.block3.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block3.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block3.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block3.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block3.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block3.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.212)\n",
       " ),\n",
       " 'backbone.enc.enc3.block3.drop_path.0': DropPath(drop_prob=0.212),\n",
       " 'backbone.enc.enc3.block4': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.229)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe': PointSequential(\n",
       "   (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.0': SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc3.block4.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block4.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block4.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block4.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block4.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block4.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.229)\n",
       " ),\n",
       " 'backbone.enc.enc3.block4.drop_path.0': DropPath(drop_prob=0.229),\n",
       " 'backbone.enc.enc3.block5': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.247)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe': PointSequential(\n",
       "   (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.0': SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc3.block5.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block5.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc3.block5.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.norm2.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc3.block5.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=384, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=1536, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=384, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=1536, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=384, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=1536, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc3.block5.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc3.block5.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.247)\n",
       " ),\n",
       " 'backbone.enc.enc3.block5.drop_path.0': DropPath(drop_prob=0.247),\n",
       " 'backbone.enc.enc4': PointSequential(\n",
       "   (down): SerializedPooling(\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): PointSequential(\n",
       "       (0): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=512, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=512, out_features=2048, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=2048, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.265)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=512, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=512, out_features=2048, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=2048, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.282)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=512, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=512, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=512, out_features=2048, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=2048, out_features=512, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.300)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down': SerializedPooling(\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): PointSequential(\n",
       "     (0): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.down.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.down.norm': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.norm.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.down.norm.0.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.down.norm.0.norm.0': BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc4.down.norm.0.norm.1': BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc4.down.norm.0.norm.2': BatchNorm1d(512, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.enc.enc4.down.act': PointSequential(\n",
       "   (0): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.enc.enc4.down.act.0': GELU(approximate='none'),\n",
       " 'backbone.enc.enc4.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=512, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=512, out_features=2048, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=2048, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.265)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe': PointSequential(\n",
       "   (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.0': SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc4.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.cpe.2.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm1.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=512, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=512, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block0.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc4.block0.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.norm2.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block0.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=512, out_features=2048, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=2048, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=512, out_features=2048, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=2048, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=512, out_features=2048, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=2048, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block0.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block0.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.265)\n",
       " ),\n",
       " 'backbone.enc.enc4.block0.drop_path.0': DropPath(drop_prob=0.265),\n",
       " 'backbone.enc.enc4.block1': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=512, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=512, out_features=2048, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=2048, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.282)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe': PointSequential(\n",
       "   (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.0': SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc4.block1.cpe.1': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.cpe.2.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm1.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=512, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv': ParametrizedLinear(\n",
       "   in_features=512, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.attn.proj': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block1.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc4.block1.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.norm2.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block1.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=512, out_features=2048, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=2048, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=512, out_features=2048, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=2048, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=512, out_features=2048, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=2048, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block1.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block1.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.282)\n",
       " ),\n",
       " 'backbone.enc.enc4.block1.drop_path.0': DropPath(drop_prob=0.282),\n",
       " 'backbone.enc.enc4.block2': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=512, out_features=1536, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=512, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=512, out_features=2048, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=2048, out_features=512, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.300)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe': PointSequential(\n",
       "   (0): SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.0': SubMConv3d(512, 512, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.enc.enc4.block2.cpe.1': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.cpe.2.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm1.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=512, out_features=1536, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=512, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv': ParametrizedLinear(\n",
       "   in_features=512, out_features=1536, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.attn.proj': ParametrizedLinear(\n",
       "   in_features=512, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.proj.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.proj.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.attn.proj.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.attn.proj_drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block2.attn.softmax': Softmax(dim=-1),\n",
       " 'backbone.enc.enc4.block2.norm2': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm2.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((512,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm.0': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm.1': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.norm2.0.norm.2': LayerNorm((512,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.enc.enc4.block2.mlp': PointSequential(\n",
       "   (0): MLP(\n",
       "     (fc1): ParametrizedLinear(\n",
       "       in_features=512, out_features=2048, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (act): GELU(approximate='none')\n",
       "     (fc2): ParametrizedLinear(\n",
       "       in_features=2048, out_features=512, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0': MLP(\n",
       "   (fc1): ParametrizedLinear(\n",
       "     in_features=512, out_features=2048, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (act): GELU(approximate='none')\n",
       "   (fc2): ParametrizedLinear(\n",
       "     in_features=2048, out_features=512, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (drop): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1': ParametrizedLinear(\n",
       "   in_features=512, out_features=2048, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.mlp.0.act': GELU(approximate='none'),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc2': ParametrizedLinear(\n",
       "   in_features=2048, out_features=512, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc2.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc2.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.mlp.0.fc2.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.enc.enc4.block2.mlp.0.drop': Dropout(p=0.0, inplace=False),\n",
       " 'backbone.enc.enc4.block2.drop_path': PointSequential(\n",
       "   (0): DropPath(drop_prob=0.300)\n",
       " ),\n",
       " 'backbone.enc.enc4.block2.drop_path.0': DropPath(drop_prob=0.300),\n",
       " 'backbone.dec': PointSequential(\n",
       "   (dec3): PointSequential(\n",
       "     (up): SerializedUnpooling(\n",
       "       (proj): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=512, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "       (proj_skip): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.300)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.273)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=384, out_features=1152, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=384, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=384, out_features=1536, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=1536, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.245)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dec2): PointSequential(\n",
       "     (up): SerializedUnpooling(\n",
       "       (proj): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=384, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "       (proj_skip): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.218)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.191)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(192, 192, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=192, out_features=576, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=192, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((192,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=192, out_features=768, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=768, out_features=192, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.164)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dec1): PointSequential(\n",
       "     (up): SerializedUnpooling(\n",
       "       (proj): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=192, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "       (proj_skip): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.136)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.109)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(96, 96, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=96, out_features=288, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=96, out_features=96, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((96,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=96, out_features=384, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=384, out_features=96, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.082)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (dec0): PointSequential(\n",
       "     (up): SerializedUnpooling(\n",
       "       (proj): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=96, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "       (proj_skip): PointSequential(\n",
       "         (0): ParametrizedLinear(\n",
       "           in_features=48, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (1): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (2): GELU(approximate='none')\n",
       "       )\n",
       "     )\n",
       "     (block0): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=64, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=64, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=64, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=64, out_features=256, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=256, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.055)\n",
       "       )\n",
       "     )\n",
       "     (block1): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=64, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=64, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=64, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=64, out_features=256, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=256, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): DropPath(drop_prob=0.027)\n",
       "       )\n",
       "     )\n",
       "     (block2): Block(\n",
       "       (cpe): PointSequential(\n",
       "         (0): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "         (1): ParametrizedLinear(\n",
       "           in_features=64, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (2): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (norm1): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (attn): SerializedAttention(\n",
       "         (qkv): ParametrizedLinear(\n",
       "           in_features=64, out_features=192, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj): ParametrizedLinear(\n",
       "           in_features=64, out_features=64, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "         (softmax): Softmax(dim=-1)\n",
       "       )\n",
       "       (norm2): PointSequential(\n",
       "         (0): PDNorm(\n",
       "           (norm): ModuleList(\n",
       "             (0-2): 3 x LayerNorm((64,), eps=0.001, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (mlp): PointSequential(\n",
       "         (0): MLP(\n",
       "           (fc1): ParametrizedLinear(\n",
       "             in_features=64, out_features=256, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (act): GELU(approximate='none')\n",
       "           (fc2): ParametrizedLinear(\n",
       "             in_features=256, out_features=64, bias=True\n",
       "             (parametrizations): ModuleDict(\n",
       "               (weight): ParametrizationList(\n",
       "                 (0): LoRAParametrization()\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): PointSequential(\n",
       "         (0): Identity()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3': PointSequential(\n",
       "   (up): SerializedUnpooling(\n",
       "     (proj): PointSequential(\n",
       "       (0): ParametrizedLinear(\n",
       "         in_features=512, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (2): GELU(approximate='none')\n",
       "     )\n",
       "     (proj_skip): PointSequential(\n",
       "       (0): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (2): GELU(approximate='none')\n",
       "     )\n",
       "   )\n",
       "   (block0): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.300)\n",
       "     )\n",
       "   )\n",
       "   (block1): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.273)\n",
       "     )\n",
       "   )\n",
       "   (block2): Block(\n",
       "     (cpe): PointSequential(\n",
       "       (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "       (1): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (norm1): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (attn): SerializedAttention(\n",
       "       (qkv): ParametrizedLinear(\n",
       "         in_features=384, out_features=1152, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj): ParametrizedLinear(\n",
       "         in_features=384, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "       (softmax): Softmax(dim=-1)\n",
       "     )\n",
       "     (norm2): PointSequential(\n",
       "       (0): PDNorm(\n",
       "         (norm): ModuleList(\n",
       "           (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (mlp): PointSequential(\n",
       "       (0): MLP(\n",
       "         (fc1): ParametrizedLinear(\n",
       "           in_features=384, out_features=1536, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (act): GELU(approximate='none')\n",
       "         (fc2): ParametrizedLinear(\n",
       "           in_features=1536, out_features=384, bias=True\n",
       "           (parametrizations): ModuleDict(\n",
       "             (weight): ParametrizationList(\n",
       "               (0): LoRAParametrization()\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (drop): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): PointSequential(\n",
       "       (0): DropPath(drop_prob=0.245)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up': SerializedUnpooling(\n",
       "   (proj): PointSequential(\n",
       "     (0): ParametrizedLinear(\n",
       "       in_features=512, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): GELU(approximate='none')\n",
       "   )\n",
       "   (proj_skip): PointSequential(\n",
       "     (0): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (2): GELU(approximate='none')\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj': PointSequential(\n",
       "   (0): ParametrizedLinear(\n",
       "     in_features=512, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (2): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj.0': ParametrizedLinear(\n",
       "   in_features=512, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.dec.dec3.up.proj.1': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj.1.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj.1.norm.0': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.dec.dec3.up.proj.1.norm.1': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.dec.dec3.up.proj.1.norm.2': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.dec.dec3.up.proj.2': GELU(approximate='none'),\n",
       " 'backbone.dec.dec3.up.proj_skip': PointSequential(\n",
       "   (0): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (1): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (2): GELU(approximate='none')\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj_skip.0': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj_skip.0.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj_skip.0.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj_skip.0.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.dec.dec3.up.proj_skip.1': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj_skip.1.norm': ModuleList(\n",
       "   (0-2): 3 x BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       " ),\n",
       " 'backbone.dec.dec3.up.proj_skip.1.norm.0': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.dec.dec3.up.proj_skip.1.norm.1': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.dec.dec3.up.proj_skip.1.norm.2': BatchNorm1d(384, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
       " 'backbone.dec.dec3.up.proj_skip.2': GELU(approximate='none'),\n",
       " 'backbone.dec.dec3.block0': Block(\n",
       "   (cpe): PointSequential(\n",
       "     (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "     (1): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm1): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (attn): SerializedAttention(\n",
       "     (qkv): ParametrizedLinear(\n",
       "       in_features=384, out_features=1152, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj): ParametrizedLinear(\n",
       "       in_features=384, out_features=384, bias=True\n",
       "       (parametrizations): ModuleDict(\n",
       "         (weight): ParametrizationList(\n",
       "           (0): LoRAParametrization()\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "     (softmax): Softmax(dim=-1)\n",
       "   )\n",
       "   (norm2): PointSequential(\n",
       "     (0): PDNorm(\n",
       "       (norm): ModuleList(\n",
       "         (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (mlp): PointSequential(\n",
       "     (0): MLP(\n",
       "       (fc1): ParametrizedLinear(\n",
       "         in_features=384, out_features=1536, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (act): GELU(approximate='none')\n",
       "       (fc2): ParametrizedLinear(\n",
       "         in_features=1536, out_features=384, bias=True\n",
       "         (parametrizations): ModuleDict(\n",
       "           (weight): ParametrizationList(\n",
       "             (0): LoRAParametrization()\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (drop): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): PointSequential(\n",
       "     (0): DropPath(drop_prob=0.300)\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.cpe': PointSequential(\n",
       "   (0): SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm)\n",
       "   (1): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.cpe.0': SubMConv3d(384, 384, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm),\n",
       " 'backbone.dec.dec3.block0.cpe.1': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.cpe.1.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.cpe.1.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.cpe.1.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.dec.dec3.block0.cpe.2': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.cpe.2.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.cpe.2.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.dec.dec3.block0.cpe.2.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.dec.dec3.block0.cpe.2.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.dec.dec3.block0.norm1': PointSequential(\n",
       "   (0): PDNorm(\n",
       "     (norm): ModuleList(\n",
       "       (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.norm1.0': PDNorm(\n",
       "   (norm): ModuleList(\n",
       "     (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.norm1.0.norm': ModuleList(\n",
       "   (0-2): 3 x LayerNorm((384,), eps=0.001, elementwise_affine=True)\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.norm1.0.norm.0': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.dec.dec3.block0.norm1.0.norm.1': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.dec.dec3.block0.norm1.0.norm.2': LayerNorm((384,), eps=0.001, elementwise_affine=True),\n",
       " 'backbone.dec.dec3.block0.attn': SerializedAttention(\n",
       "   (qkv): ParametrizedLinear(\n",
       "     in_features=384, out_features=1152, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj): ParametrizedLinear(\n",
       "     in_features=384, out_features=384, bias=True\n",
       "     (parametrizations): ModuleDict(\n",
       "       (weight): ParametrizationList(\n",
       "         (0): LoRAParametrization()\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "   (softmax): Softmax(dim=-1)\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.attn.qkv': ParametrizedLinear(\n",
       "   in_features=384, out_features=1152, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.attn.qkv.parametrizations': ModuleDict(\n",
       "   (weight): ParametrizationList(\n",
       "     (0): LoRAParametrization()\n",
       "   )\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.attn.qkv.parametrizations.weight': ParametrizationList(\n",
       "   (0): LoRAParametrization()\n",
       " ),\n",
       " 'backbone.dec.dec3.block0.attn.qkv.parametrizations.weight.0': LoRAParametrization(),\n",
       " 'backbone.dec.dec3.block0.attn.proj': ParametrizedLinear(\n",
       "   in_features=384, out_features=384, bias=True\n",
       "   (parametrizations): ModuleDict(\n",
       "     (weight): ParametrizationList(\n",
       "       (0): LoRAParametrization()\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ecf224-51ec-4344-9eea-364e854ed0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in model.named_modules():\n",
    "#     print(k, v)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff3c868-354c-4251-9d3c-de175ac71b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module backbone.enc.enc0.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc0.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.down.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc1.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.down.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc2.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.down.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block3.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block3.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block3.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block3.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block3.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block4.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block4.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block4.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block4.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block4.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block5.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block5.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block5.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block5.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc3.block5.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.down.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.enc.enc4.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.up.proj.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.up.proj_skip.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec3.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.up.proj.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.up.proj_skip.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec2.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.up.proj.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.up.proj_skip.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec1.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.up.proj.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.up.proj_skip.0:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block0.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block0.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block0.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block0.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block0.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block1.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block1.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block1.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block1.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block1.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block2.cpe.1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block2.attn.qkv:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block2.attn.proj:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block2.mlp.0.fc1:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module backbone.dec.dec0.block2.mlp.0.fc2:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n",
      "Module proj_head:\n",
      "  - weight LoRA parameters:\n",
      "    - original: device = cuda:0\n",
      "    - 0.lora_A: device = cuda:0\n",
      "    - 0.lora_B: device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "def showlora(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d, nn.MultiheadAttention)):\n",
    "            print(f\"Module {name}:\")\n",
    "            if hasattr(module, 'parametrizations'):\n",
    "                for param_name, param in module.parametrizations.items():\n",
    "                    print(f\"  - {param_name} LoRA parameters:\")\n",
    "                    for lora_name, lora_param in param.named_parameters():\n",
    "                        print(f\"    - {lora_name}: device = {lora_param.device}\")\n",
    "            elif isinstance(module, nn.MultiheadAttention):\n",
    "                if hasattr(module.out_proj, 'parametrizations'):\n",
    "                    for param_name, param in module.out_proj.parametrizations.items():\n",
    "                        print(f\"  - out_proj.{param_name} LoRA parameters:\")\n",
    "                        for lora_name, lora_param in param.named_parameters():\n",
    "                            print(f\"    - {lora_name}: device = {lora_param.device}\")\n",
    "\n",
    "showlora(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd82726-a2ce-4fc5-bcb2-54535a6d7460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7011af-0d97-46b4-94a0-e4b2707e46c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba4a57-ab4c-47d7-b9bf-bb32267bab67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8478a-94cd-41cc-bb66-168c02e22551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca56452-a63a-41a3-ad42-a7afc0df6d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd04c52-fdca-464d-943c-3373fc528132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef7074-15d7-463d-942b-c6f1facae827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bd2de-5b12-45c3-9f35-abcdc24c64b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516088c-9a06-457e-8b55-df4ca94f2d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df44cae0-ba50-4ca3-ad1a-3e8cdd5cd0d1",
   "metadata": {},
   "source": [
    "### custom implementation (claude, unchecked but it runs lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56f4925-2b1d-4961-afc5-6c98cf7a39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=4):\n",
    "        super().__init__()\n",
    "        self.lora_A = nn.Parameter(torch.zeros(rank, in_features))\n",
    "        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))\n",
    "        self.scale = 0.01\n",
    "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x @ self.lora_A.T @ self.lora_B.T) * self.scale\n",
    "\n",
    "class AdaptiveLoRAWrapper(nn.Module):\n",
    "    def __init__(self, base_layer, rank=4):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        if hasattr(base_layer, 'weight'):\n",
    "            weight = base_layer.weight\n",
    "            in_features, out_features = weight.shape[1], weight.shape[0]\n",
    "        elif hasattr(base_layer, 'in_features') and hasattr(base_layer, 'out_features'):\n",
    "            in_features, out_features = base_layer.in_features, base_layer.out_features\n",
    "        else:\n",
    "            raise ValueError(f\"Unable to determine in_features and out_features for {type(base_layer)}\")\n",
    "        self.lora = LoRALayer(in_features, out_features, rank)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_layer(x) + self.lora(x)\n",
    "\n",
    "def get_in_out_features(layer):\n",
    "    if hasattr(layer, 'in_features') and hasattr(layer, 'out_features'):\n",
    "        return layer.in_features, layer.out_features\n",
    "    elif hasattr(layer, 'weight'):\n",
    "        return layer.weight.shape[1], layer.weight.shape[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to determine in_features and out_features for {type(layer)}\")\n",
    "\n",
    "class LoRAQKV(nn.Module):\n",
    "    def __init__(self, qkv_layer, rank=4):\n",
    "        super().__init__()\n",
    "        self.qkv_layer = qkv_layer\n",
    "        in_features, out_features = get_in_out_features(qkv_layer)\n",
    "        self.lora = LoRALayer(in_features, out_features, rank)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.qkv_layer(x) + self.lora(x)\n",
    "\n",
    "def apply_lora_to_ptv3(model, rank=4):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, SerializedAttention):\n",
    "            module.qkv = LoRAQKV(module.qkv, rank)\n",
    "            module.proj = AdaptiveLoRAWrapper(module.proj, rank)\n",
    "        elif isinstance(module, MLP):\n",
    "            module.fc1 = AdaptiveLoRAWrapper(module.fc1, rank)\n",
    "            module.fc2 = AdaptiveLoRAWrapper(module.fc2, rank)\n",
    "\n",
    "def apply_lora_to_ppt(model, rank=4):\n",
    "    # Apply LoRA to PT-v3 backbone\n",
    "    apply_lora_to_ptv3(model.backbone, rank)\n",
    "    \n",
    "    # Apply LoRA to the projection head\n",
    "    model.proj_head = AdaptiveLoRAWrapper(model.proj_head, rank)\n",
    "\n",
    "    def freeze_non_lora_params(model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'lora' not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    freeze_non_lora_params(model)\n",
    "    return model\n",
    "\n",
    "# Usage:\n",
    "# ppt_model = PointPromptTraining(...)\n",
    "# ppt_model_with_lora = apply_lora_to_ppt(ppt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cb43c1-07d4-4dbd-8750-996c067d5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_model_with_lora = apply_lora_to_ppt(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e371a72-40b1-4b14-b25f-849320d726a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointcept.models.point_transformer_v3 import SerializedAttention, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b62fda-35af-416b-bb18-00942c4fa9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453888"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(ppt_model_with_lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b67cec-fe12-465d-92e6-b09f227082d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97979580"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d061f4e-b415-4cce-b5ce-68fb2f8b1a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
