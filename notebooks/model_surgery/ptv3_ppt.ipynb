{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97aa1631-bdf1-446f-8a7a-12eb0de74245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-26 17:24:07,655 INFO test.py line 41 49502] => Loading config ...\n",
      "[2024-08-26 17:24:07,656 INFO test.py line 48 49502] => Building model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj_head shape says Linear(in_features=64, out_features=512, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-26 17:24:10,408 INFO test.py line 61 49502] Num params: 97447088\n",
      "[2024-08-26 17:24:10,610 INFO test.py line 68 49502] Loading weight at: ../../models/PointTransformerV3/scannet-semseg-pt-v3m1-1-ppt-extreme/model/model_best.pth\n",
      "[2024-08-26 17:24:11,214 INFO test.py line 84 49502] => Loaded weight '../../models/PointTransformerV3/scannet-semseg-pt-v3m1-1-ppt-extreme/model/model_best.pth' (epoch 94)\n",
      "[2024-08-26 17:24:11,218 INFO test.py line 53 49502] => Building test dataset & dataloader ...\n",
      "[2024-08-26 17:24:11,220 INFO scannet.py line 72 49502] Totally 0 x 1 samples in val set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DITCHING CLASS EMBEDDING\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import webbrowser\n",
    "import graphviz\n",
    "graphviz.set_jupyter_format('svg')\n",
    "from lora_pytorch import LoRA\n",
    "assert torch.cuda.is_available()\n",
    "from torchview import draw_graph\n",
    "from torchviz import make_dot\n",
    "from graphviz import Digraph\n",
    "\n",
    "from pointcept.engines.defaults import (\n",
    "    default_argument_parser,\n",
    "    default_config_parser,\n",
    "    default_setup,\n",
    ")\n",
    "from pointcept.engines.test import TESTERS\n",
    "from pointcept.engines.launch import launch\n",
    "from pointcept.engines.test import TesterBase, SemSegTester\n",
    "\n",
    "repo_root = Path(\"../..\")\n",
    "\n",
    "\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def create_spoofed_input(batch_size=2, num_points=1000, n_classes=5, num_features=6, device='cpu'):\n",
    "    return {\n",
    "        'coord': torch.rand(num_points * batch_size, num_features, device=device),\n",
    "        'feat': torch.rand(num_points * batch_size, num_features, device=device),\n",
    "        'grid_coord': torch.randint(0, 100, (num_points * batch_size, 3), device=device),\n",
    "        'batch': torch.arange(batch_size, device=device).repeat_interleave(num_points),\n",
    "        'offset': torch.tensor([num_points * i for i in range(1, batch_size + 1)], device=device),\n",
    "        'condition': ['ScanNet'] * batch_size,\n",
    "        'grid_size': torch.tensor([0.01], device=device),\n",
    "        'segment': torch.randint(low=0, high=n_classes-1, size=(num_points * batch_size,), device=device)\n",
    "    }\n",
    "\n",
    "\n",
    "def patch_cfg(cfg: dict, repo_root: Path = repo_root) -> dict:\n",
    "    cfg = cfg.copy()\n",
    "    cfg[\"my_data_root\"] = repo_root / cfg[\"my_data_root\"]\n",
    "    cfg[\"weight\"] = repo_root / cfg[\"weight\"]\n",
    "    cfg[\"batch_size_test_per_gpu\"] = 1\n",
    "    return cfg\n",
    "\n",
    "\n",
    "repo_root = Path(\"../..\")\n",
    "cfg_file = Path(\"../../test/custom-ppt-config.py\"); assert cfg_file.exists\n",
    "device = \"cuda\"\n",
    "\n",
    "args = default_argument_parser().parse_args(args=[\"--config-file\", f\"{cfg_file}\"])\n",
    "cfg = default_config_parser(args.config_file, args.options); cfg = patch_cfg(cfg)\n",
    "\n",
    "tester = TESTERS.build(dict(type=cfg.test.type, cfg=cfg))\n",
    "model = tester.model\n",
    "model.to(device)\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4c725-2926-43b7-aed2-9f348530cc91",
   "metadata": {},
   "source": [
    "# Visualise netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f17df69-85bb-4481-9c82-d4b36bd058b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece78c4e-df11-4a38-9175-75309a337b1b",
   "metadata": {},
   "source": [
    "Now install netron and open this file:\n",
    "\n",
    "```bash\n",
    "snap install netron\n",
    "snap run netron\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92870c6-b661-422a-8542-a3b7f0e4bac7",
   "metadata": {},
   "source": [
    "# LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301b9e8-b406-44e0-9e8e-0ed4f5a8ba81",
   "metadata": {},
   "source": [
    "Compare implementations, need to understand wtf is going on in lora-pytorch with the custom MHA implementation and why this isn't necessary in the pytora + claude-generated solutions\n",
    "\n",
    "maybe need to compare param counts and see the difference in their behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac3631-feea-49f9-9dc2-d8ac19297e51",
   "metadata": {},
   "source": [
    "### lora-pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf019940-a66c-402d-ae71-f164b94cf3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bare model:  110759388\n",
      "lora: 13312300\n"
     ]
    }
   ],
   "source": [
    "lora_model = LoRA.from_module(model, rank=50)\n",
    "print(\"bare model: \", count_trainable_parameters(model))\n",
    "print(\"lora:\", count_trainable_parameters(lora_model))\n",
    "torch.save(model, \"model_lora.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76140c1e-d0ec-4dbf-bb16-2f62dc4fc47c",
   "metadata": {},
   "source": [
    "### pytora implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe6fbb5-2525-4ba2-8bd5-eaaed1102c1c",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf183b0f-3960-4586-ace2-567cb7365ded",
   "metadata": {},
   "source": [
    "### minlora implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0772a9-0b33-40be-a432-b997c9e34f33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "249031c8-7288-4f6a-ade9-1c0c76ad785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA applied to blocks.0.attention.out_proj: False\n",
      "LoRA applied to blocks.0.ffn.0: True\n",
      "LoRA applied to blocks.0.ffn.2: True\n",
      "LoRA applied to blocks.0.conv: True\n",
      "LoRA applied to blocks.1.attention.out_proj: False\n",
      "LoRA applied to blocks.1.ffn.0: True\n",
      "LoRA applied to blocks.1.ffn.2: True\n",
      "LoRA applied to blocks.1.conv: True\n",
      "LoRA applied to blocks.2.attention.out_proj: False\n",
      "LoRA applied to blocks.2.ffn.0: True\n",
      "LoRA applied to blocks.2.ffn.2: True\n",
      "LoRA applied to blocks.2.conv: True\n",
      "LoRA applied to final_layer: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from minlora import add_lora, LoRAParametrization\n",
    "\n",
    "# Example custom architecture\n",
    "class CustomBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(dim, 8)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, 4*dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*dim, dim)\n",
    "        )\n",
    "        self.conv = nn.Conv2d(dim, dim, 3, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.attention(x, x, x)[0] + x\n",
    "        x = self.ffn(x) + x\n",
    "        x = x.permute(0, 2, 1).unsqueeze(-1)  # reshape for 2D conv\n",
    "        x = self.conv(x).squeeze(-1).permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, dim, num_blocks):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([CustomBlock(dim) for _ in range(num_blocks)])\n",
    "        self.final_layer = nn.Linear(dim, dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return self.final_layer(x)\n",
    "\n",
    "# Custom LoRA configuration\n",
    "custom_lora_config = {\n",
    "    nn.Linear: {\n",
    "        \"weight\": LoRAParametrization.from_linear\n",
    "    },\n",
    "    # nn.MultiheadAttention: {\n",
    "    #     \"out_proj.weight\": LoRAParametrization.from_linear\n",
    "    # },\n",
    "    nn.Conv2d: {\n",
    "        \"weight\": LoRAParametrization.from_conv2d\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create and apply LoRA\n",
    "model = CustomModel(dim=256, num_blocks=3)\n",
    "add_lora(model, lora_config=custom_lora_config)\n",
    "\n",
    "# Verify LoRA application\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (nn.Linear, nn.Conv2d)) or (isinstance(module, nn.MultiheadAttention) and 'weight' in name):\n",
    "        print(f\"LoRA applied to {name}: {hasattr(module, 'parametrizations')}\")\n",
    "\n",
    "# # Training loop (pseudo-code)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = criterion(model(batch), targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e317bc98-49b3-45eb-b9f7-7881112a0ae3",
   "metadata": {},
   "source": [
    "#### for PPT+PTvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47b67844-b7be-4072-be00-36475b883e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import minlora\n",
    "from minlora import (\n",
    "    LoRAParametrization,\n",
    "    add_lora,\n",
    "    merge_lora,\n",
    "    remove_lora\n",
    ")\n",
    "from minlora.model import add_lora_by_name, apply_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27230259-4488-4bb1-a727-34fe57fab909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before LoRA: 97447088\n",
      "after LoRA: 532492\n"
     ]
    }
   ],
   "source": [
    "# optimizer\n",
    "def configure_optimizers_lora(self, weight_decay, learning_rate, betas, device_type):\n",
    "    # we apply weight decay to all lora params\n",
    "    optim_groups = [\n",
    "        # note: .get_lora_params() returns a generator\n",
    "        # we need to wrap it in a list so we can consume it twice\n",
    "        {\"params\": list(minlora.get_lora_params(self)) , \"weight_decay\": weight_decay},\n",
    "        # you can also add biases for fine-tuning,\n",
    "        # but I want to make sure lora alone works\n",
    "        # {\"params\": minlora.get_bias_params(self), \"weight_decay\": 0.0}, # bias params don't get weight decay\n",
    "    ]\n",
    "\n",
    "    def parameter_count(optim_groups):\n",
    "        n = sum(p.numel() for group in optim_groups for p in group[\"params\"])\n",
    "        if n < 1e6:\n",
    "            return f\"{n/1e3:.1f}k\"\n",
    "        else:\n",
    "            return f\"{n/1e6:.1f}M\"\n",
    "\n",
    "    print(f\"optimizing {parameter_count(optim_groups)} parameters\")\n",
    "\n",
    "    # new PyTorch nightly has a new 'fused' option for AdamW that is much faster\n",
    "    use_fused = (device_type == \"cuda\") and (\"fused\" in inspect.signature(torch.optim.AdamW).parameters)\n",
    "    print(f\"using fused AdamW: {use_fused}\")\n",
    "    extra_args = dict(fused=True) if use_fused else dict()\n",
    "    optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "lora_dropout_p = 0.0\n",
    "rank=4\n",
    "lora_alpha = 64\n",
    "lora_config = {\n",
    "    torch.nn.Embedding: {\n",
    "        \"weight\": partial(LoRAParametrization.from_embedding, rank=rank, lora_alpha=lora_alpha),\n",
    "    },\n",
    "    torch.nn.Linear: {\n",
    "        \"weight\": partial(LoRAParametrization.from_linear, rank=rank, lora_alpha=lora_alpha),\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"before LoRA:\", count_trainable_parameters(model))\n",
    "\n",
    "def freeze_non_lora_params(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if True:#'lora' not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "freeze_non_lora_params(model)\n",
    "\n",
    "minlora.add_lora(model, lora_config=lora_config)\n",
    "print(\"after LoRA:\", count_trainable_parameters(model))\n",
    "# if use_lora:\n",
    "#     optimizer = configure_optimizers_lora(model, weight_decay, learning_rate, (beta1, beta2), device_type)\n",
    "# else:\n",
    "#     optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)\n",
    "# if init_from == 'resume':\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ecf224-51ec-4344-9eea-364e854ed0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in model.named_modules():\n",
    "#     print(k, v)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a1c11-c210-48aa-875b-7149c75dae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba05cad3-cf39-4a1a-b2b5-2721c70144c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97979580"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff3c868-354c-4251-9d3c-de175ac71b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showlora(model):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d, nn.MultiheadAttention)):\n",
    "            print(f\"Module {name}:\")\n",
    "            if hasattr(module, 'parametrizations'):\n",
    "                for param_name, param in module.parametrizations.items():\n",
    "                    print(f\"  - {param_name} LoRA parameters:\")\n",
    "                    for lora_name, lora_param in param.named_parameters():\n",
    "                        print(f\"    - {lora_name}: device = {lora_param.device}\")\n",
    "            elif isinstance(module, nn.MultiheadAttention):\n",
    "                if hasattr(module.out_proj, 'parametrizations'):\n",
    "                    for param_name, param in module.out_proj.parametrizations.items():\n",
    "                        print(f\"  - out_proj.{param_name} LoRA parameters:\")\n",
    "                        for lora_name, lora_param in param.named_parameters():\n",
    "                            print(f\"    - {lora_name}: device = {lora_param.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd82726-a2ce-4fc5-bcb2-54535a6d7460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7011af-0d97-46b4-94a0-e4b2707e46c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba4a57-ab4c-47d7-b9bf-bb32267bab67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8478a-94cd-41cc-bb66-168c02e22551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca56452-a63a-41a3-ad42-a7afc0df6d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd04c52-fdca-464d-943c-3373fc528132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef7074-15d7-463d-942b-c6f1facae827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bd2de-5b12-45c3-9f35-abcdc24c64b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516088c-9a06-457e-8b55-df4ca94f2d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df44cae0-ba50-4ca3-ad1a-3e8cdd5cd0d1",
   "metadata": {},
   "source": [
    "### custom implementation (claude, unchecked but it runs lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56f4925-2b1d-4961-afc5-6c98cf7a39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, rank=4):\n",
    "        super().__init__()\n",
    "        self.lora_A = nn.Parameter(torch.zeros(rank, in_features))\n",
    "        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))\n",
    "        self.scale = 0.01\n",
    "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x @ self.lora_A.T @ self.lora_B.T) * self.scale\n",
    "\n",
    "class AdaptiveLoRAWrapper(nn.Module):\n",
    "    def __init__(self, base_layer, rank=4):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        if hasattr(base_layer, 'weight'):\n",
    "            weight = base_layer.weight\n",
    "            in_features, out_features = weight.shape[1], weight.shape[0]\n",
    "        elif hasattr(base_layer, 'in_features') and hasattr(base_layer, 'out_features'):\n",
    "            in_features, out_features = base_layer.in_features, base_layer.out_features\n",
    "        else:\n",
    "            raise ValueError(f\"Unable to determine in_features and out_features for {type(base_layer)}\")\n",
    "        self.lora = LoRALayer(in_features, out_features, rank)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_layer(x) + self.lora(x)\n",
    "\n",
    "def get_in_out_features(layer):\n",
    "    if hasattr(layer, 'in_features') and hasattr(layer, 'out_features'):\n",
    "        return layer.in_features, layer.out_features\n",
    "    elif hasattr(layer, 'weight'):\n",
    "        return layer.weight.shape[1], layer.weight.shape[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Unable to determine in_features and out_features for {type(layer)}\")\n",
    "\n",
    "class LoRAQKV(nn.Module):\n",
    "    def __init__(self, qkv_layer, rank=4):\n",
    "        super().__init__()\n",
    "        self.qkv_layer = qkv_layer\n",
    "        in_features, out_features = get_in_out_features(qkv_layer)\n",
    "        self.lora = LoRALayer(in_features, out_features, rank)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.qkv_layer(x) + self.lora(x)\n",
    "\n",
    "def apply_lora_to_ptv3(model, rank=4):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, SerializedAttention):\n",
    "            module.qkv = LoRAQKV(module.qkv, rank)\n",
    "            module.proj = AdaptiveLoRAWrapper(module.proj, rank)\n",
    "        elif isinstance(module, MLP):\n",
    "            module.fc1 = AdaptiveLoRAWrapper(module.fc1, rank)\n",
    "            module.fc2 = AdaptiveLoRAWrapper(module.fc2, rank)\n",
    "\n",
    "def apply_lora_to_ppt(model, rank=4):\n",
    "    # Apply LoRA to PT-v3 backbone\n",
    "    apply_lora_to_ptv3(model.backbone, rank)\n",
    "    \n",
    "    # Apply LoRA to the projection head\n",
    "    model.proj_head = AdaptiveLoRAWrapper(model.proj_head, rank)\n",
    "\n",
    "    def freeze_non_lora_params(model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'lora' not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "    freeze_non_lora_params(model)\n",
    "    return model\n",
    "\n",
    "# Usage:\n",
    "# ppt_model = PointPromptTraining(...)\n",
    "# ppt_model_with_lora = apply_lora_to_ppt(ppt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cb43c1-07d4-4dbd-8750-996c067d5c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_model_with_lora = apply_lora_to_ppt(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e371a72-40b1-4b14-b25f-849320d726a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointcept.models.point_transformer_v3 import SerializedAttention, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b62fda-35af-416b-bb18-00942c4fa9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453888"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(ppt_model_with_lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b67cec-fe12-465d-92e6-b09f227082d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97979580"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d061f4e-b415-4cce-b5ce-68fb2f8b1a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
