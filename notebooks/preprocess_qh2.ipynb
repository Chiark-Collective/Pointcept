{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f119e9a-ecde-4793-9b6b-e3c1a3fb04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import laspy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "las_subsampled_path = '/data/sdd/training_v2_subsampled_centroid_0.05.las'\n",
    "pth_input_path = '/home/sogilvy/Pointcept/notebooks/output_file_norm.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e062c09a-acf0-4c5e-835a-e9c47f7897ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAS file version: 1.4\n",
      "LAS file version: 1.4\n"
     ]
    }
   ],
   "source": [
    "def print_las_version(file_path):\n",
    "    with laspy.open(file_path) as file:\n",
    "        header = file.header\n",
    "        # Access the version directly from the header\n",
    "        version = header.version\n",
    "        print(f\"LAS file version: {version}\")\n",
    "\n",
    "# Replace 'path_to_your_file.las' with the path to your LAS file\n",
    "print_las_version('/data/sdd/training_v2_subsampled_centroid_0.05.las')\n",
    "print_las_version('/data/sdd/training_v2.las')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d2279f-eeec-47d8-ae63-053efad45a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def partition_pth_file(input_pth_path, base_output_directory, num_voxels_x, num_voxels_y, num_voxels_z):\n",
    "    # Load the data from the .pth file\n",
    "    data = torch.load(input_pth_path)\n",
    "\n",
    "    # Extract coordinates and convert to numpy for processing\n",
    "    coords = data['coord']\n",
    "\n",
    "    # Calculate the bounds and voxel sizes\n",
    "    min_coords = coords.min(axis=0)\n",
    "    max_coords = coords.max(axis=0)\n",
    "    voxel_size = (max_coords - min_coords) / np.array([num_voxels_x, num_voxels_y, num_voxels_z])\n",
    "\n",
    "    # Calculate voxel indices for each point\n",
    "    voxel_indices = np.floor((coords - min_coords) / voxel_size).astype(int)\n",
    "    voxel_indices = np.clip(voxel_indices, 0, [num_voxels_x-1, num_voxels_y-1, num_voxels_z-1])\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(base_output_directory, exist_ok=True)\n",
    "\n",
    "    # Loop over all voxels\n",
    "    for ix in range(num_voxels_x):\n",
    "        for iy in range(num_voxels_y):\n",
    "            for iz in range(num_voxels_z):\n",
    "                # Find points in this voxel\n",
    "                voxel_mask = (voxel_indices[:, 0] == ix) & (voxel_indices[:, 1] == iy) & (voxel_indices[:, 2] == iz)\n",
    "                if voxel_mask.any():\n",
    "                    voxel_data = {key: data[key][voxel_mask] for key in data if isinstance(data[key], np.ndarray)}\n",
    "                    voxel_data['scene_id'] = data['scene_id']  # Carry over the scene_id unchanged\n",
    "\n",
    "                    # Path for the new split file\n",
    "                    voxel_file_path = os.path.join(base_output_directory, f'voxel_{ix}_{iy}_{iz}.pth')\n",
    "                    torch.save(voxel_data, voxel_file_path)\n",
    "\n",
    "    print(f\"All voxel files saved in {base_output_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b95efd7-7bdd-4d34-a040-cb29acf115e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All voxel files saved in /data/sdd/qh/vox6res0.2\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "num_vox = 6\n",
    "num_voxels_x, num_voxels_y, num_voxels_z = num_vox, num_vox, num_vox  # Specify the number of voxels in each dimension\n",
    "base_output_directory = f'/data/sdd/qh/vox{num_vox}res0.2'\n",
    "pth_input_path = '/data/sdd/training_v2_subsampled_centroid_0.02.pth'\n",
    "partition_pth_file(pth_input_path, base_output_directory, num_voxels_x, num_voxels_y, num_voxels_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e1886-7c40-4177-9808-d62f3f148014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pointcept)",
   "language": "python",
   "name": "pointcept"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
