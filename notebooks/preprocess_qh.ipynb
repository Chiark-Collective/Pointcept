{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9448b0c0-f5ea-4c85-8a18-4377fab00e01",
   "metadata": {},
   "source": [
    "# Preprocessing the Queen's House dataset\n",
    "\n",
    "We need to get the QH input data compatible with what Pointcept will expect.\n",
    "\n",
    "To that end, let's first take a look at the preprocessed Scannet data. We'll check the test data which lacks the ground truth for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9414cad9-c6a6-4c07-8cfa-abde98aff5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import laspy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b76ae0-27f3-403f-8869-b233d3156c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the contents of the loaded file and details of numpy arrays\n",
    "def print_structure(data, indent=0):\n",
    "    for key, value in data.items():\n",
    "        print('    ' * indent + f'{key}: ', end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_structure(value, indent+1)\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(f'{type(value)}')\n",
    "            print('    ' * (indent + 1) + f'Shape: {value.shape}')\n",
    "            print('    ' * (indent + 1) + f'Dtype: {value.dtype}')\n",
    "            # Improved presentation of first few elements respecting the shape\n",
    "            preview_elements = value[:min(5, value.shape[0])] if value.ndim > 1 else value[:min(5, value.size)]\n",
    "            print('    ' * (indent + 1) + 'First few elements:')\n",
    "            for elem in preview_elements:\n",
    "                print('    ' * (indent + 2) + str(elem))\n",
    "        elif isinstance(value, torch.Tensor):\n",
    "            print(f'{type(value)}')\n",
    "            print('    ' * (indent + 1) + f'Shape: {value.shape}')\n",
    "            print('    ' * (indent + 1) + f'Dtype: {value.dtype}')\n",
    "            print('    ' * (indent + 1) + 'First few elements:')\n",
    "            # Ensure tensor is on CPU for numpy conversion and print\n",
    "            preview_tensor = value[:min(5, value.size(0))] if value.dim() > 1 else value[:min(5, value.numel())]\n",
    "            if value.requires_grad:\n",
    "                preview_tensor = preview_tensor.detach()\n",
    "            preview_tensor = preview_tensor.cpu().numpy()  # Convert to numpy array for easier handling\n",
    "            for elem in preview_tensor:\n",
    "                print('    ' * (indent + 2) + str(elem))\n",
    "        if isinstance(value, str):\n",
    "            print(type(value), value)\n",
    "        else:\n",
    "            print(type(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0446aa9d-a2f6-4b3e-9db4-dcd2f6a37787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'numpy.ndarray'>\n",
      "    Shape: (94940, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [0.8089936 1.7126828 0.4325   ]\n",
      "        [0.80993974 1.7030041  0.4375    ]\n",
      "        [0.81063616 1.7958345  0.43055147]\n",
      "        [0.8068326  1.707043   0.48693752]\n",
      "        [0.81019104 1.7423848  0.40600002]\n",
      "<class 'numpy.ndarray'>\n",
      "color: <class 'numpy.ndarray'>\n",
      "    Shape: (94940, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [65. 31. 12.]\n",
      "        [57. 37. 14.]\n",
      "        [47. 21.  6.]\n",
      "        [61. 40. 21.]\n",
      "        [62. 32. 19.]\n",
      "<class 'numpy.ndarray'>\n",
      "scene_id: <class 'str'> scene0731_00\n",
      "normal: <class 'numpy.ndarray'>\n",
      "    Shape: (94940, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [0.9951747  0.07436273 0.06389181]\n",
      "        [0.99502224 0.08380412 0.05370668]\n",
      "        [ 0.9969072  -0.06340786  0.04612521]\n",
      "        [0.99583614 0.08168959 0.04035537]\n",
      "        [0.9973334  0.02651416 0.06789085]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Path to the .pth file\n",
    "file_path = '../data/scannet/test/scene0731_00.pth'\n",
    "\n",
    "# Load the contents of the .pth file\n",
    "data = torch.load(file_path)\n",
    "\n",
    "\n",
    "\n",
    "# Call the function to print the structure\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6b8ee-cbdb-49c9-8348-022529d83202",
   "metadata": {},
   "source": [
    "So, we have numpy arrays where each element is a len-3 array with:\n",
    "- coord\n",
    "- color\n",
    "- normal\n",
    "and then a scene id string for the file.\n",
    "\n",
    "Now, the normals in the Scannet preprocessing script are optional - we may not need them in the final model, so ignore them for now. If we do need them, or we need them to acquire an acceptable performance, we'll have to use the same mesh reconstruction algorithms used in things like Scannet - those are documented on their github and use well-established algorithms, should be feasible to implement for our data.\n",
    "\n",
    "\n",
    "# QH .las files\n",
    "\n",
    "Let's get a small snippet that can show what the .las file structure is like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e90f5d7-b2db-4ab4-b545-e70d066a3435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension names:\n",
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'synthetic', 'key_point', 'withheld', 'overlap', 'scanner_channel', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'user_data', 'scan_angle', 'point_source_id', 'gps_time', 'red', 'green', 'blue', 'newtax', 'uniclass']\n",
      "Extra dimension names:\n",
      "['newtax', 'uniclass']\n",
      "52\n",
      "Number of points: 278681989\n",
      "X coordinates: <ScaledArrayView([538739.77  538738.235 538738.651 538738.941 538739.187 538739.486\n",
      " 538739.826 538738.029 538738.323 538738.682])>\n",
      "Y coordinates: <ScaledArrayView([177749.354 177752.248 177751.495 177750.967 177750.523 177749.98\n",
      " 177749.365 177752.755 177752.22  177751.567])>\n",
      "Z coordinates: <ScaledArrayView([8.978 8.969 8.987 8.983 8.97  8.971 8.98  8.983 8.976 8.982])>\n",
      "red coordinates: [46336 46848 46080 46336 46592 46080 44800 43264 43008 42240]\n",
      "Intensity values: [6966 7224 6708 7224 6192 7224 7740 5418 3870 7740]\n",
      "Classifications: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "\n",
    "def read_las_file(file_path):\n",
    "    # Open the LAS file\n",
    "    with laspy.open(file_path) as file:\n",
    "        for points in file.chunk_iterator(1):\n",
    "            print(\"Dimension names:\")\n",
    "            print(list(points.point_format.dimension_names))\n",
    "            print(\"Extra dimension names:\")\n",
    "            print(list(points.point_format.extra_dimension_names))\n",
    "            print(points.point_size)\n",
    "            \n",
    "            break\n",
    "        # Read the point records from the file\n",
    "        las = file.read()\n",
    "\n",
    "        # Accessing specific data dimensions\n",
    "        points = las.points\n",
    "        x_coordinates = las.x\n",
    "        y_coordinates = las.y\n",
    "        z_coordinates = las.z\n",
    "        red_coordinates = las.red\n",
    "\n",
    "        # Optionally, access other attributes like intensity, classification, etc.\n",
    "        intensity = las.intensity\n",
    "        classifications = las.classification\n",
    "\n",
    "        # Print some basic information about the LAS file\n",
    "        print(f\"Number of points: {len(points)}\")\n",
    "        print(f\"X coordinates: {x_coordinates[:10]}\")  # Print first 10 for brevity\n",
    "        print(f\"Y coordinates: {y_coordinates[:10]}\")\n",
    "        print(f\"Z coordinates: {z_coordinates[:10]}\")\n",
    "        print(f\"red coordinates: {red_coordinates[:10]}\")\n",
    "        print(f\"Intensity values: {intensity[:10]}\")\n",
    "        print(f\"Classifications: {classifications[:10]}\")\n",
    "\n",
    "# Specify the path to your .las file\n",
    "file_path = '/data/sdd/training_v2.las'\n",
    "read_las_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3119ba4-02eb-4a30-be5c-dd09615c6d3a",
   "metadata": {},
   "source": [
    "So, first thing we need a func that can take this .las file and generate a pytorch state dictionary with it.\n",
    "\n",
    "Can set up a function to iterate over the requested number of points for testing purposes. If we need to we can extend this script with ground truth info, normal calculations, everything that Pointcept might require.\n",
    "\n",
    "May also need to look into putting this into the Pointcept package proper as part of the registry, which I'm still figuring out...\n",
    "\n",
    "## .las converter\n",
    "\n",
    "So now want some code to convert .las files into whatever format we want. Start with a basic function that can take an input file, and some naive number of points to convert, and outputs a .pth file in a format Pointcept should be able to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f501102d-7b71-4fbc-91cc-fca87ea044a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 points to output_file.pth\n"
     ]
    }
   ],
   "source": [
    "def las_to_pth(input_las_path, output_pth_path, num_points):\n",
    "    # Open the LAS file and read data\n",
    "    with laspy.open(input_las_path) as file:\n",
    "        las = file.read()\n",
    "\n",
    "        # Ensure num_points does not exceed the number of points in the file\n",
    "        max_points = min(num_points, len(las.points))\n",
    "\n",
    "        # Create the coord array (n x 3) for coordinates\n",
    "        coord = np.stack((las.x[:max_points], las.y[:max_points], las.z[:max_points]), axis=-1).astype(np.float32)\n",
    "\n",
    "        # Check if RGB data exists and create the color array (n x 3) for color data\n",
    "        if hasattr(las, 'red') and hasattr(las, 'green') and hasattr(las, 'blue'):\n",
    "            # Convert RGB from uint16 to float32 directly within np.stack\n",
    "            color = np.stack((las.red[:max_points], las.green[:max_points], las.blue[:max_points]), axis=-1).astype(np.float32)\n",
    "            # Normalize RGB values if necessary (typical range in LAS is 0 to 65535)\n",
    "            color /= 256.0  # Normalize to [0, 1] if you prefer to work with normalized colors\n",
    "        else:\n",
    "            color = np.zeros((max_points, 3), dtype=np.float32)  # Default to black if no color data available\n",
    "            print(\"RGB data not found in LAS file. Defaulting to black for color.\")\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        tensors = {\n",
    "            'coord': torch.tensor(coord, dtype=torch.float32),\n",
    "            'color': torch.tensor(color, dtype=torch.float32),\n",
    "            'scene_id': \"scene9999_00\",\n",
    "        }\n",
    "\n",
    "    # Save the dictionary as a PyTorch state dictionary (.pth file)\n",
    "    torch.save(tensors, output_pth_path)\n",
    "    print(f\"Saved {max_points} points to {output_pth_path}\")\n",
    "\n",
    "# Specify the input LAS file, output PTH file path, and number of points\n",
    "input_las_path = '/data/sdd/training_v2.las'\n",
    "output_pth_path = 'output_file.pth'\n",
    "num_points = 1000  # Number of points to process and save\n",
    "\n",
    "# Call the function\n",
    "las_to_pth(input_las_path, output_pth_path, num_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984bfc2-fd8e-42fc-a2d8-eeffaa5ff3c8",
   "metadata": {},
   "source": [
    "Now lets read the output and check it matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4c63f9-bf9d-49f5-96a8-b212397e340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([1000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [5.3873944e+05 1.7774992e+05 8.9729996e+00]\n",
      "        [5.3873975e+05 1.7774936e+05 8.9779997e+00]\n",
      "        [5.3873825e+05 1.7775225e+05 8.9689999e+00]\n",
      "        [5.387386e+05 1.777515e+05 8.987000e+00]\n",
      "        [5.3873894e+05 1.7775097e+05 8.9829998e+00]\n",
      "<class 'torch.Tensor'>\n",
      "color: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([1000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [188. 197. 168.]\n",
      "        [181. 189. 165.]\n",
      "        [183. 192. 161.]\n",
      "        [180. 189. 158.]\n",
      "        [181. 193. 157.]\n",
      "<class 'torch.Tensor'>\n",
      "scene_id: <class 'str'> scene9999_00\n"
     ]
    }
   ],
   "source": [
    "# Load the contents of the .pth file\n",
    "data = torch.load(output_pth_path)\n",
    "\n",
    "# Call the function to print the structure\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae06315-93a6-4312-9f49-8ca5baa3a3c3",
   "metadata": {},
   "source": [
    "As I recall from looking at Pointcept's data readers, it can handle torch tensors so even if this doesn't look *exactly* like the Scannet data with it's numpy arrays, this should be *technically* fine as input to Pointcept assuming normals are optional.\n",
    "\n",
    "As for if the data has the necessary numerical characteristics to be processed properly, we note that the QH data for the x, y, z length scales have large offsets compared to the scannet data for x, y.\n",
    "\n",
    "Maybe we should get min-max for x, y, z for both the Scannet and QH datasets and compare them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdbd9468-e5b7-4d71-995b-b65cccd2d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X range: 538698.605 to 538742.333, Difference: 43.728000000002794\n",
      "Y range: 177690.766 to 177752.815, Difference: 62.04899999999907\n",
      "Z range: 6.697 to 29.134, Difference: 22.437\n"
     ]
    }
   ],
   "source": [
    "def las_min_max_ranges(input_las_path):\n",
    "    # Open the LAS file and read data\n",
    "    with laspy.open(input_las_path) as file:\n",
    "        las = file.read()\n",
    "\n",
    "        # Calculate min and max for x, y, and z\n",
    "        x_min, x_max = las.x.min(), las.x.max()\n",
    "        y_min, y_max = las.y.min(), las.y.max()\n",
    "        z_min, z_max = las.z.min(), las.z.max()\n",
    "\n",
    "        # Calculate differences\n",
    "        x_range = x_max - x_min\n",
    "        y_range = y_max - y_min\n",
    "        z_range = z_max - z_min\n",
    "\n",
    "    print(f\"X range: {x_min} to {x_max}, Difference: {x_range}\")\n",
    "    print(f\"Y range: {y_min} to {y_max}, Difference: {y_range}\")\n",
    "    print(f\"Z range: {z_min} to {z_max}, Difference: {z_range}\")\n",
    "\n",
    "# Example usage:\n",
    "las_min_max_ranges('/data/sdd/training_v2.las')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5788daa4-9145-4afd-b229-c601f63ee189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X range: 0.56696617603302 to 4.752572059631348\n",
      "Y range: 0.31187281012535095 to 3.864165782928467\n",
      "Z range: -0.012044666334986687 to 2.501612901687622\n",
      "\n",
      "X range: 0.7937601804733276 to 10.793277740478516\n",
      "Y range: -0.05707528442144394 to 4.980363845825195\n",
      "Z range: 0.0002449717721901834 to 3.1450295448303223\n"
     ]
    }
   ],
   "source": [
    "def pth_min_max_ranges_single(input_pth_path):\n",
    "    # Load the state dictionary from a .pth file\n",
    "    data = torch.load(input_pth_path)\n",
    "\n",
    "    # Assuming 'coord' tensor is [n x 3] for x, y, z\n",
    "    coord = data['coord']\n",
    "\n",
    "    # Calculate min and max for x, y, and z\n",
    "    x_min, x_max = coord[:, 0].min().item(), coord[:, 0].max().item()\n",
    "    y_min, y_max = coord[:, 1].min().item(), coord[:, 1].max().item()\n",
    "    z_min, z_max = coord[:, 2].min().item(), coord[:, 2].max().item()\n",
    "\n",
    "    print(f\"X range: {x_min} to {x_max}\")\n",
    "    print(f\"Y range: {y_min} to {y_max}\")\n",
    "    print(f\"Z range: {z_min} to {z_max}\")\n",
    "\n",
    "# Example usage:\n",
    "pth_min_max_ranges_single('../data/scannet/test/scene0731_00.pth')\n",
    "print()\n",
    "pth_min_max_ranges_single('../data/scannet/test/scene0744_00.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b0a90-d480-4544-8dab-dd0e9877652a",
   "metadata": {},
   "source": [
    "Let's check all the scannet data min-max ranges at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fc620e0-f388-4660-9cbb-f1317d544b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X range across all files: -2.1278457641601562 to 17.116708755493164\n",
      "Total Y range across all files: -1.4605504274368286 to 18.189441680908203\n",
      "Total Z range across all files: -0.37873902916908264 to 6.966972827911377\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def pth_min_max_ranges(directory):\n",
    "    # Recursively find all .pth files in the given directory\n",
    "    pth_files = glob.glob(os.path.join(directory, '**/*.pth'), recursive=True)\n",
    "\n",
    "    # Initialize min and max values to None initially\n",
    "    x_min, x_max = None, None\n",
    "    y_min, y_max = None, None\n",
    "    z_min, z_max = None, None\n",
    "\n",
    "    for file_path in pth_files:\n",
    "        # Load the state dictionary from a .pth file\n",
    "        data = torch.load(file_path)\n",
    "\n",
    "        # Assuming 'coord' tensor is [n x 3] for x, y, z\n",
    "        coord = data['coord']\n",
    "\n",
    "        # Calculate min and max for each file and update global min/max\n",
    "        if x_min is None:\n",
    "            # Initialize min/max values with the first file's values\n",
    "            x_min, x_max = coord[:, 0].min(), coord[:, 0].max()\n",
    "            y_min, y_max = coord[:, 1].min(), coord[:, 1].max()\n",
    "            z_min, z_max = coord[:, 2].min(), coord[:, 2].max()\n",
    "        else:\n",
    "            # Update min/max values based on this file's data\n",
    "            x_min = min(x_min, coord[:, 0].min())\n",
    "            x_max = max(x_max, coord[:, 0].max())\n",
    "            y_min = min(y_min, coord[:, 1].min())\n",
    "            y_max = max(y_max, coord[:, 1].max())\n",
    "            z_min = min(z_min, coord[:, 2].min())\n",
    "            z_max = max(z_max, coord[:, 2].max())\n",
    "\n",
    "    print(f\"Total X range across all files: {x_min.item()} to {x_max.item()}\")\n",
    "    print(f\"Total Y range across all files: {y_min.item()} to {y_max.item()}\")\n",
    "    print(f\"Total Z range across all files: {z_min.item()} to {z_max.item()}\")\n",
    "\n",
    "# Example usage:\n",
    "directory_path = '../data/scannet'\n",
    "pth_min_max_ranges(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3462d-43d5-4b37-8795-6f9042886c88",
   "metadata": {},
   "source": [
    "So, between minus a couple to just under 20 on Scannet. Let's check S3DIS too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48279306-58ae-4aea-99ea-89081b74ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X range across all files: -37.928 to 29.927\n",
      "Total Y range across all files: -26.078 to 46.05599999999999\n",
      "Total Z range across all files: -2.6450000000000005 to 6.576\n"
     ]
    }
   ],
   "source": [
    "pth_min_max_ranges(\"../data/s3dis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961ab43-6c7a-4c11-9bb4-34c87b534c30",
   "metadata": {},
   "source": [
    "So, broadly similar for S3DIS, plus-minus O(10^2).\n",
    "\n",
    "I'm unsure how to treat the negative coords in these datasets... might not need to worry about them for now, maybe Pointcept is \"smart\" enough to just work with data with all positive coords. Seems the majority are positive anyway.\n",
    "\n",
    "We can modify our .las converter file to remove these large x,y offsets for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca19b639-14bc-407a-9a20-da2b5ff14b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def las_to_pth(input_las_path, output_pth_path, num_points, norm_z=True):\n",
    "    # Open the LAS file and read data\n",
    "    with laspy.open(input_las_path) as file:\n",
    "        las = file.read()\n",
    "\n",
    "        # Ensure num_points does not exceed the number of points in the file\n",
    "        max_points = min(num_points, len(las.points))\n",
    "\n",
    "        # Read coordinates and adjust them to start at zero\n",
    "        x_adjusted = las.x[:max_points] - np.min(las.x[:max_points])\n",
    "        y_adjusted = las.y[:max_points] - np.min(las.y[:max_points])\n",
    "        \n",
    "        if norm_z:\n",
    "            z = las.z[:max_points] - np.min(las.z[:max_points])\n",
    "        else:\n",
    "            z = las.z[:max_points]  # Z adjustment is not requested but can be done similarly\n",
    "\n",
    "        # Create the coord array (n x 3) for adjusted coordinates\n",
    "        coord = np.stack((x_adjusted, y_adjusted, z), axis=-1).astype(np.float32)\n",
    "\n",
    "        # Check if RGB data exists and create the color array (n x 3) for color data\n",
    "        if hasattr(las, 'red') and hasattr(las, 'green') and hasattr(las, 'blue'):\n",
    "            # Convert RGB from uint16 to float32 directly within np.stack\n",
    "            color = np.stack((las.red[:max_points], las.green[:max_points], las.blue[:max_points]), axis=-1).astype(np.float32)\n",
    "            # Normalize RGB values if necessary (typical range in LAS is 0 to 65535)\n",
    "            color /= 256.0  # Normalize to [0, 1] if you prefer to work with normalized colors\n",
    "        else:\n",
    "            color = np.zeros((max_points, 3), dtype=np.float32)  # Default to black if no color data available\n",
    "            print(\"RGB data not found in LAS file. Defaulting to black for color.\")\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        tensors = {\n",
    "            'coord': torch.tensor(coord, dtype=torch.float32),\n",
    "            'color': torch.tensor(color, dtype=torch.float32),\n",
    "            'scene_id': \"scene9999_00\"\n",
    "        }\n",
    "\n",
    "    # Save the dictionary as a PyTorch state dictionary (.pth file)\n",
    "    torch.save(tensors, output_pth_path)\n",
    "    print(f\"Saved {max_points} points to {output_pth_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad7fe3bc-e978-43cf-813b-bd667abb4f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 points to output_file_norm.pth\n"
     ]
    }
   ],
   "source": [
    "# Specify the input LAS file, output PTH file path, and number of points\n",
    "input_las_path = '/data/sdd/training_v2.las'\n",
    "output_pth_path = 'output_file_norm.pth'\n",
    "num_points = 10000  # Number of points to process and save\n",
    "\n",
    "# Call the function\n",
    "las_to_pth(input_las_path, output_pth_path, num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10c9891e-62f8-449f-ad15-9d20ebda0dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([10000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [1.55  0.634 0.061]\n",
      "        [1.868 0.059 0.066]\n",
      "        [0.333 2.953 0.057]\n",
      "        [0.749 2.2   0.075]\n",
      "        [1.039 1.672 0.071]\n",
      "<class 'torch.Tensor'>\n",
      "color: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([10000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [188. 197. 168.]\n",
      "        [181. 189. 165.]\n",
      "        [183. 192. 161.]\n",
      "        [180. 189. 158.]\n",
      "        [181. 193. 157.]\n",
      "<class 'torch.Tensor'>\n",
      "scene_id: <class 'str'> scene9999_00\n",
      "\n",
      "X range: 0.0 to 4.431000232696533\n",
      "Y range: 0.0 to 3.5199999809265137\n",
      "Z range: 0.0 to 0.1770000010728836\n"
     ]
    }
   ],
   "source": [
    "# Load the contents of the .pth file\n",
    "data = torch.load(output_pth_path)\n",
    "\n",
    "# Call the function to print the structure\n",
    "print_structure(data)\n",
    "print()\n",
    "\n",
    "pth_min_max_ranges_single(output_pth_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c52983-5b0c-47c5-a686-69911f326021",
   "metadata": {},
   "source": [
    "I note that this is a very very crude approach, we'll very likely have to do a smarter coordinate normalisation in our preprocessing, even if it seems like Pointcept handles a lot of normalisation inside the \"black box\" itself and not in preprocessing.\n",
    "\n",
    "# Plugging this data into Pointcept\n",
    "\n",
    "So now we have converted a chunk of QH data into something that looks superficially reasonable for a scannet/s3dis dataset, can we just plug this into a Pointcept config file and run some inference with it?\n",
    "\n",
    "Time to dig into the config file format and see if we can configure a job that just runs inference. If not we'll maybe need to spoof some ground-truth values.\n",
    "\n",
    "Let's have a look at what the ground truth values look like in the Scannet processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "340a2c21-5e1f-4e22-8a12-df2818ec744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'numpy.ndarray'>\n",
      "    Shape: (237360, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [2.5091114  0.4083811  0.14877559]\n",
      "        [2.5156426  0.4059527  0.14168811]\n",
      "        [2.5073788  0.4145141  0.14327997]\n",
      "        [2.5004458  0.40534744 0.1462612 ]\n",
      "        [2.5201747  0.47421882 0.15652634]\n",
      "<class 'numpy.ndarray'>\n",
      "color: <class 'numpy.ndarray'>\n",
      "    Shape: (237360, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [35. 33. 38.]\n",
      "        [34. 32. 39.]\n",
      "        [40. 35. 43.]\n",
      "        [35. 33. 38.]\n",
      "        [31. 30. 31.]\n",
      "<class 'numpy.ndarray'>\n",
      "scene_id: <class 'str'> scene0011_00\n",
      "normal: <class 'numpy.ndarray'>\n",
      "    Shape: (237360, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [0.19109516 0.92176497 0.3371149 ]\n",
      "        [0.35799062 0.9311391  0.06885417]\n",
      "        [ 0.59007823 -0.42843354  0.684249  ]\n",
      "        [0.2563957  0.11805225 0.9592446 ]\n",
      "        [ 0.819725   -0.5543586   0.14370042]\n",
      "<class 'numpy.ndarray'>\n",
      "semantic_gt20: <class 'numpy.ndarray'>\n",
      "    Shape: (237360,)\n",
      "    Dtype: int64\n",
      "    First few elements:\n",
      "        14\n",
      "        14\n",
      "        14\n",
      "        14\n",
      "        14\n",
      "<class 'numpy.ndarray'>\n",
      "semantic_gt200: <class 'numpy.ndarray'>\n",
      "    Shape: (237360,)\n",
      "    Dtype: int64\n",
      "    First few elements:\n",
      "        23\n",
      "        23\n",
      "        23\n",
      "        23\n",
      "        23\n",
      "<class 'numpy.ndarray'>\n",
      "instance_gt: <class 'numpy.ndarray'>\n",
      "    Shape: (237360,)\n",
      "    Dtype: int64\n",
      "    First few elements:\n",
      "        27\n",
      "        27\n",
      "        27\n",
      "        27\n",
      "        27\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "file_path = '../data/scannet/val/scene0011_00.pth'\n",
    "data = torch.load(file_path)\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f0f29-ce83-4b07-8a11-6b1f0179d311",
   "metadata": {},
   "source": [
    "So we have the ground truth for Scannet20, 200, and an \"instance_gt\" which might be a general label? Let's check the scannet preprocessing script to see what this gt actually is.\n",
    "\n",
    "```python\n",
    " # Generate new labels\n",
    "        semantic_gt20 = np.ones((vertices.shape[0])) * IGNORE_INDEX\n",
    "        semantic_gt200 = np.ones((vertices.shape[0])) * IGNORE_INDEX\n",
    "        instance_ids = np.ones((vertices.shape[0])) * IGNORE_INDEX\n",
    "        for group in seg_groups:\n",
    "            point_idx, label_id20, label_id200 = point_indices_from_group(\n",
    "                seg_indices, group, labels_pd\n",
    "            )\n",
    "\n",
    "            semantic_gt20[point_idx] = label_id20\n",
    "            semantic_gt200[point_idx] = label_id200\n",
    "            instance_ids[point_idx] = group[\"id\"]\n",
    "\n",
    "        semantic_gt20 = semantic_gt20.astype(int)\n",
    "        semantic_gt200 = semantic_gt200.astype(int)\n",
    "        instance_ids = instance_ids.astype(int)\n",
    "\n",
    "        save_dict[\"semantic_gt20\"] = semantic_gt20\n",
    "        save_dict[\"semantic_gt200\"] = semantic_gt200\n",
    "        save_dict[\"instance_gt\"] = instance_ids\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07dac84-a333-4c54-83e7-eb8ef51fb508",
   "metadata": {},
   "source": [
    "## Normal spoofing\n",
    "\n",
    "So turns out we need normals for a strict scannet set. For the time being I'm just going to spoof some normal vectors and run with it, then we'll introduce our own datasets and see if normals are required or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169727b0-d3ba-4b71-91ff-d4f3cf5240dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def las_to_pth(input_las_path, output_pth_path, num_points):\n",
    "    # Open the LAS file and read data\n",
    "    with laspy.open(input_las_path) as file:\n",
    "        las = file.read()\n",
    "\n",
    "        # Ensure num_points does not exceed the number of points in the file\n",
    "        max_points = min(num_points, len(las.points))\n",
    "\n",
    "        # Create the coord array (n x 3) for coordinates\n",
    "        coord = np.stack((las.x[:max_points], las.y[:max_points], las.z[:max_points]), axis=-1).astype(np.float32)\n",
    "\n",
    "        # Check if RGB data exists and create the color array (n x 3) for color data\n",
    "        if hasattr(las, 'red') and hasattr(las, 'green') and hasattr(las, 'blue'):\n",
    "            # Convert RGB from uint16 to float32 directly within np.stack\n",
    "            color = np.stack((las.red[:max_points], las.green[:max_points], las.blue[:max_points]), axis=-1).astype(np.float32)\n",
    "            # Normalize RGB values if necessary (typical range in LAS is 0 to 65535)\n",
    "            color /= 256.0  # Normalize to [0, 1] if you prefer to work with normalized colors\n",
    "        else:\n",
    "            color = np.zeros((max_points, 3), dtype=np.float32)  # Default to black if no color data available\n",
    "            print(\"RGB data not found in LAS file. Defaulting to black for color.\")\n",
    "\n",
    "        # Generate random normals and normalize them\n",
    "        normal = np.random.rand(max_points, 3).astype(np.float32)\n",
    "        norm = np.linalg.norm(normal, axis=1, keepdims=True)\n",
    "        normal /= norm  # Normalize to unit vectors\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        tensors = {\n",
    "            'coord': torch.tensor(coord, dtype=torch.float32),\n",
    "            'color': torch.tensor(color, dtype=torch.float32),\n",
    "            'normal': torch.tensor(normal, dtype=torch.float32),\n",
    "            'scene_id': \"scene9999_00\"  # Add a top-level string object with a dummy value\n",
    "        }\n",
    "\n",
    "    # Save the dictionary as a PyTorch state dictionary (.pth file)\n",
    "    torch.save(tensors, output_pth_path)\n",
    "    print(f\"Saved {max_points} points to {output_pth_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5cfaef9-8bc1-4a3e-84bc-8e966a365161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 points to output_file_norm.pth\n"
     ]
    }
   ],
   "source": [
    "# Specify the input LAS file, output PTH file path, and number of points\n",
    "input_las_path = '/data/sdd/training_v2.las'\n",
    "output_pth_path = 'output_file_norm.pth'\n",
    "num_points = 1000000  # Number of points to process and save\n",
    "\n",
    "# Call the function\n",
    "las_to_pth(input_las_path, output_pth_path, num_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f081e2e-e349-4124-aa96-1719e0ef3bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([10000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [5.3873944e+05 1.7774992e+05 8.9729996e+00]\n",
      "        [5.3873975e+05 1.7774936e+05 8.9779997e+00]\n",
      "        [5.3873825e+05 1.7775225e+05 8.9689999e+00]\n",
      "        [5.387386e+05 1.777515e+05 8.987000e+00]\n",
      "        [5.3873894e+05 1.7775097e+05 8.9829998e+00]\n",
      "<class 'torch.Tensor'>\n",
      "color: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([10000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [188. 197. 168.]\n",
      "        [181. 189. 165.]\n",
      "        [183. 192. 161.]\n",
      "        [180. 189. 158.]\n",
      "        [181. 193. 157.]\n",
      "<class 'torch.Tensor'>\n",
      "normal: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([10000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [0.47011682 0.23847726 0.8497757 ]\n",
      "        [0.20806971 0.5027224  0.8390335 ]\n",
      "        [0.5014625  0.17515276 0.84726435]\n",
      "        [0.7702582  0.5183476  0.37150773]\n",
      "        [0.59888804 0.3688299  0.71084285]\n",
      "<class 'torch.Tensor'>\n",
      "scene_id: <class 'str'> scene9999_00\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(output_pth_path)\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a775469c-fa2c-41cf-8090-d38b1ab9645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def las_to_np_pth(input_las_path, output_pth_path, num_points, scene_id, spoof_normal=True, spoof_gt=True):\n",
    "    # Open the LAS file and read data\n",
    "    with laspy.open(input_las_path) as file:\n",
    "        las = file.read()\n",
    "\n",
    "        # Ensure num_points does not exceed the number of points in the file\n",
    "        max_points = min(num_points, len(las.points))\n",
    "\n",
    "        # Read coordinates and adjust them to start at zero\n",
    "        x_adjusted = las.x[:max_points] - np.min(las.x[:max_points])\n",
    "        y_adjusted = las.y[:max_points] - np.min(las.y[:max_points])\n",
    "        z_adjusted = las.z[:max_points] - np.min(las.z[:max_points])\n",
    "        \n",
    "        # Create the coord array (n x 3) for coordinates\n",
    "        # coord = np.stack((las.x[:max_points], las.y[:max_points], las.z[:max_points]), axis=-1).astype(np.float32)\n",
    "        coord = np.stack((x_adjusted, y_adjusted, z_adjusted), axis=-1).astype(np.float32)\n",
    "        \n",
    "        # Check if RGB data exists and create the color array (n x 3) for color data\n",
    "        if hasattr(las, 'red') and hasattr(las, 'green') and hasattr(las, 'blue'):\n",
    "            color = np.stack((las.red[:max_points], las.green[:max_points], las.blue[:max_points]), axis=-1).astype(np.float32)\n",
    "            color /= 256.0  # Normalize to [0, 1] if you prefer to work with normalized colors\n",
    "        else:\n",
    "            color = np.zeros((max_points, 3), dtype=np.float32)  # Default to black if no color data available\n",
    "            print(\"RGB data not found in LAS file. Defaulting to black for color.\")\n",
    "\n",
    "        # Generate random normals and normalize them\n",
    "        normal = np.random.rand(max_points, 3).astype(np.float32)\n",
    "        norm = np.linalg.norm(normal, axis=1, keepdims=True)\n",
    "        normal /= norm\n",
    "\n",
    "        # Save numpy arrays into a dictionary and then to a .pth file\n",
    "        data = {\n",
    "            'coord': coord,\n",
    "            'color': color,\n",
    "            'scene_id': scene_id,\n",
    "        }\n",
    "\n",
    "        if spoof_normal:\n",
    "            # Generate random normals and normalize them\n",
    "            normal = np.random.rand(max_points, 3).astype(np.float32)\n",
    "            norm = np.linalg.norm(normal, axis=1, keepdims=True)\n",
    "            normal /= norm\n",
    "            data['normal'] = normal\n",
    "\n",
    "        if spoof_gt:\n",
    "            semantic_gt20 = np.random.randint(0, 20, size=max_points, dtype=np.int64)\n",
    "            data['semantic_gt20'] = semantic_gt20\n",
    "        \n",
    "        # Save the dictionary as a .pth file\n",
    "        torch.save(data, output_pth_path)\n",
    "        print(f\"Saved {max_points} points to {output_pth_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3f1156-7534-4170-9bb1-3529c32a0da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2012921 points to output_file_norm.pth\n"
     ]
    }
   ],
   "source": [
    "# input_las_path = '/data/sdd/training_v2.las'\n",
    "input_las_path = '/data/sdd/training_v2_subsampled_centroid_0.05.las'\n",
    "output_pth_path = 'output_file_norm.pth'\n",
    "las_to_np_pth(input_las_path, output_pth_path, int(1e9), \"scene0011_00\", spoof_normal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c313781c-87a7-4531-b79a-3cda765ed71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'numpy.ndarray'>\n",
      "    Shape: (2012921, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [13.32   0.015  4.674]\n",
      "        [13.375  0.016  4.678]\n",
      "        [1.3419e+01 6.0000e-03 4.6690e+00]\n",
      "        [13.422  0.015  4.723]\n",
      "        [1.3437e+01 1.1000e-02 4.7550e+00]\n",
      "<class 'numpy.ndarray'>\n",
      "color: <class 'numpy.ndarray'>\n",
      "    Shape: (2012921, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [165. 164. 146.]\n",
      "        [166. 161. 142.]\n",
      "        [68. 70. 57.]\n",
      "        [91. 92. 86.]\n",
      "        [179. 178. 176.]\n",
      "<class 'numpy.ndarray'>\n",
      "scene_id: <class 'str'> scene0011_00\n",
      "normal: <class 'numpy.ndarray'>\n",
      "    Shape: (2012921, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [0.14092363 0.35768595 0.92314744]\n",
      "        [0.5125484  0.85069805 0.11664961]\n",
      "        [0.69072914 0.722919   0.01677639]\n",
      "        [0.6820378  0.00235367 0.7313131 ]\n",
      "        [0.7649099  0.40326482 0.502285  ]\n",
      "<class 'numpy.ndarray'>\n",
      "semantic_gt20: <class 'numpy.ndarray'>\n",
      "    Shape: (2012921,)\n",
      "    Dtype: int64\n",
      "    First few elements:\n",
      "        18\n",
      "        12\n",
      "        11\n",
      "        13\n",
      "        16\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(output_pth_path)\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "329fda84-f08d-4dd3-8d57-35f915f1e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: <class 'numpy.ndarray'>\n",
      "    Shape: (10000,)\n",
      "    Dtype: int64\n",
      "    First few elements:\n",
      "         1\n",
      "         1\n",
      "         1\n",
      "         1\n",
      "         1\n"
     ]
    }
   ],
   "source": [
    "def print_npy_file_contents(npy_file_path):\n",
    "    # Load the numpy array from the .npy file\n",
    "    array = np.load(npy_file_path)\n",
    "    \n",
    "    # Print type, shape, and data type of the array\n",
    "    print(\"Array:\", type(array))\n",
    "    print(\"    Shape:\", array.shape)\n",
    "    print(\"    Dtype:\", array.dtype)\n",
    "    \n",
    "    # Print first few elements of the array\n",
    "    print(\"    First few elements:\")\n",
    "    # Limit the number of elements to print, for example, print the first 5 elements\n",
    "    preview_count = min(5, array.size)  # Use min to avoid index error for small arrays\n",
    "    for index in range(preview_count):\n",
    "        print(\"        \", array.flat[index])  # Use flat indexing for simplicity\n",
    "\n",
    "# Example usage\n",
    "npy_file_path = '../exp/test/semseg-pt-v3m1-1-ppt-extreme/result/scene0011_00_pred.npy'\n",
    "print_npy_file_contents(npy_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a120d0d-eacf-4593-a156-2dc54af473be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the array: [1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def array_to_series_and_show_values(npy_file_path):\n",
    "    # Load the numpy array from the .npy file\n",
    "    array = np.load(npy_file_path)\n",
    "    \n",
    "    # Convert the numpy array to a pandas Series\n",
    "    series = pd.Series(array)\n",
    "    \n",
    "    # Get unique values present in the Series\n",
    "    unique_values = series.unique()\n",
    "    \n",
    "    # Print the unique values\n",
    "    print(\"Unique values in the array:\", unique_values)\n",
    "\n",
    "    # Optionally, return the Series if you want to use it later\n",
    "    return series\n",
    "npy_file_path = '../exp/test/semseg-pt-v3m1-1-ppt-extreme/result/scene0011_00_pred.npy'\n",
    "series = array_to_series_and_show_values(npy_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bfaf763-c86e-4985-aa71-5ca8f79aecda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "9995    1\n",
       "9996    1\n",
       "9997    1\n",
       "9998    1\n",
       "9999    1\n",
       "Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ac4051-0a1f-4187-ad3a-504489235712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'numpy.ndarray'>\n",
      "    Shape: (10178, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [ 0.028 22.564  3.568]\n",
      "        [ 0.024 22.561  3.624]\n",
      "        [ 0.035 22.561  3.677]\n",
      "        [1.9000e-02 2.2551e+01 3.8380e+00]\n",
      "        [ 0.023 22.571  4.48 ]\n",
      "<class 'numpy.ndarray'>\n",
      "color: <class 'numpy.ndarray'>\n",
      "    Shape: (10178, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [163. 163. 171.]\n",
      "        [173. 168. 174.]\n",
      "        [123. 132. 131.]\n",
      "        [129. 133. 142.]\n",
      "        [185. 185. 175.]\n",
      "<class 'numpy.ndarray'>\n",
      "normal: <class 'numpy.ndarray'>\n",
      "    Shape: (10178, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [0.8561319  0.40729362 0.3180411 ]\n",
      "        [0.5704726  0.38740727 0.7242076 ]\n",
      "        [0.9515962  0.29082394 0.09942879]\n",
      "        [0.36304554 0.8517998  0.37767047]\n",
      "        [0.59822357 0.79330564 0.11311374]\n",
      "<class 'numpy.ndarray'>\n",
      "semantic_gt20: <class 'numpy.ndarray'>\n",
      "    Shape: (10178,)\n",
      "    Dtype: int64\n",
      "    First few elements:\n",
      "        8\n",
      "        5\n",
      "        12\n",
      "        8\n",
      "        18\n",
      "<class 'numpy.ndarray'>\n",
      "scene_id: <class 'str'> scene0011_00\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/sogilvy/Pointcept/notebooks/output_voxels/voxel_0_1_0.pth\"\n",
    "# Load the contents of the .pth file\n",
    "data = torch.load(file_path)\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb137f5-f8bf-4513-b315-4512647c5ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pointcept)",
   "language": "python",
   "name": "pointcept"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
