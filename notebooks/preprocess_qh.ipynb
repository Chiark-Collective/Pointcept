{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9448b0c0-f5ea-4c85-8a18-4377fab00e01",
   "metadata": {},
   "source": [
    "# Preprocessing the Queen's House dataset\n",
    "\n",
    "We need to get the QH input data compatible with what Pointcept will expect.\n",
    "\n",
    "To that end, let's first take a look at the preprocessed Scannet data. We'll check the test data which lacks the ground truth for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9414cad9-c6a6-4c07-8cfa-abde98aff5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0446aa9d-a2f6-4b3e-9db4-dcd2f6a37787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'numpy.ndarray'>\n",
      "    Shape: (94940, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [0.8089936 1.7126828 0.4325   ]\n",
      "        [0.80993974 1.7030041  0.4375    ]\n",
      "        [0.81063616 1.7958345  0.43055147]\n",
      "        [0.8068326  1.707043   0.48693752]\n",
      "        [0.81019104 1.7423848  0.40600002]\n",
      "<class 'numpy.ndarray'>\n",
      "color: <class 'numpy.ndarray'>\n",
      "    Shape: (94940, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [65. 31. 12.]\n",
      "        [57. 37. 14.]\n",
      "        [47. 21.  6.]\n",
      "        [61. 40. 21.]\n",
      "        [62. 32. 19.]\n",
      "<class 'numpy.ndarray'>\n",
      "scene_id: <class 'str'> scene0731_00\n",
      "normal: <class 'numpy.ndarray'>\n",
      "    Shape: (94940, 3)\n",
      "    Dtype: float32\n",
      "    First few elements:\n",
      "        [0.9951747  0.07436273 0.06389181]\n",
      "        [0.99502224 0.08380412 0.05370668]\n",
      "        [ 0.9969072  -0.06340786  0.04612521]\n",
      "        [0.99583614 0.08168959 0.04035537]\n",
      "        [0.9973334  0.02651416 0.06789085]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Path to the .pth file\n",
    "file_path = '../data/scannet/test/scene0731_00.pth'\n",
    "\n",
    "# Load the contents of the .pth file\n",
    "data = torch.load(file_path)\n",
    "\n",
    "# Function to print the contents of the loaded file and details of numpy arrays\n",
    "def print_structure(data, indent=0):\n",
    "    for key, value in data.items():\n",
    "        print('    ' * indent + f'{key}: ', end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_structure(value, indent+1)\n",
    "        elif isinstance(value, np.ndarray):\n",
    "            print(f'{type(value)}')\n",
    "            print('    ' * (indent + 1) + f'Shape: {value.shape}')\n",
    "            print('    ' * (indent + 1) + f'Dtype: {value.dtype}')\n",
    "            # Improved presentation of first few elements respecting the shape\n",
    "            preview_elements = value[:min(5, value.shape[0])] if value.ndim > 1 else value[:min(5, value.size)]\n",
    "            print('    ' * (indent + 1) + 'First few elements:')\n",
    "            for elem in preview_elements:\n",
    "                print('    ' * (indent + 2) + str(elem))\n",
    "        elif isinstance(value, torch.Tensor):\n",
    "            print(f'{type(value)}')\n",
    "            print('    ' * (indent + 1) + f'Shape: {value.shape}')\n",
    "            print('    ' * (indent + 1) + f'Dtype: {value.dtype}')\n",
    "            print('    ' * (indent + 1) + 'First few elements:')\n",
    "            # Ensure tensor is on CPU for numpy conversion and print\n",
    "            preview_tensor = value[:min(5, value.size(0))] if value.dim() > 1 else value[:min(5, value.numel())]\n",
    "            if value.requires_grad:\n",
    "                preview_tensor = preview_tensor.detach()\n",
    "            preview_tensor = preview_tensor.cpu().numpy()  # Convert to numpy array for easier handling\n",
    "            for elem in preview_tensor:\n",
    "                print('    ' * (indent + 2) + str(elem))\n",
    "        if isinstance(value, str):\n",
    "            print(type(value), value)\n",
    "        else:\n",
    "            print(type(value))\n",
    "\n",
    "# Call the function to print the structure\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6b8ee-cbdb-49c9-8348-022529d83202",
   "metadata": {},
   "source": [
    "So, we have numpy arrays where each element is a len-3 array with:\n",
    "- coord\n",
    "- color\n",
    "- normal\n",
    "and then a scene id string for the file.\n",
    "\n",
    "Now, the normals in the Scannet preprocessing script are optional - we may not need them in the final model, so ignore them for now. If we do need them, or we need them to acquire an acceptable performance, we'll have to use the same mesh reconstruction algorithms used in things like Scannet - those are documented on their github and use well-established algorithms, should be feasible to implement for our data.\n",
    "\n",
    "\n",
    "# QH .las files\n",
    "\n",
    "Let's get a small snippet that can show what the .las file structure is like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e90f5d7-b2db-4ab4-b545-e70d066a3435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension names:\n",
      "['X', 'Y', 'Z', 'intensity', 'return_number', 'number_of_returns', 'synthetic', 'key_point', 'withheld', 'overlap', 'scanner_channel', 'scan_direction_flag', 'edge_of_flight_line', 'classification', 'user_data', 'scan_angle', 'point_source_id', 'gps_time', 'red', 'green', 'blue', 'newtax', 'uniclass']\n",
      "Extra dimension names:\n",
      "['newtax', 'uniclass']\n",
      "52\n",
      "Number of points: 278681989\n",
      "X coordinates: <ScaledArrayView([538739.77  538738.235 538738.651 538738.941 538739.187 538739.486\n",
      " 538739.826 538738.029 538738.323 538738.682])>\n",
      "Y coordinates: <ScaledArrayView([177749.354 177752.248 177751.495 177750.967 177750.523 177749.98\n",
      " 177749.365 177752.755 177752.22  177751.567])>\n",
      "Z coordinates: <ScaledArrayView([8.978 8.969 8.987 8.983 8.97  8.971 8.98  8.983 8.976 8.982])>\n",
      "red coordinates: [46336 46848 46080 46336 46592 46080 44800 43264 43008 42240]\n",
      "Intensity values: [6966 7224 6708 7224 6192 7224 7740 5418 3870 7740]\n",
      "Classifications: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "\n",
    "def read_las_file(file_path):\n",
    "    # Open the LAS file\n",
    "    with laspy.open(file_path) as file:\n",
    "        for points in file.chunk_iterator(1):\n",
    "            print(\"Dimension names:\")\n",
    "            print(list(points.point_format.dimension_names))\n",
    "            print(\"Extra dimension names:\")\n",
    "            print(list(points.point_format.extra_dimension_names))\n",
    "            print(points.point_size)\n",
    "            \n",
    "            break\n",
    "        # Read the point records from the file\n",
    "        las = file.read()\n",
    "\n",
    "        # Accessing specific data dimensions\n",
    "        points = las.points\n",
    "        x_coordinates = las.x\n",
    "        y_coordinates = las.y\n",
    "        z_coordinates = las.z\n",
    "        red_coordinates = las.red\n",
    "\n",
    "        # Optionally, access other attributes like intensity, classification, etc.\n",
    "        intensity = las.intensity\n",
    "        classifications = las.classification\n",
    "\n",
    "        # Print some basic information about the LAS file\n",
    "        print(f\"Number of points: {len(points)}\")\n",
    "        print(f\"X coordinates: {x_coordinates[:10]}\")  # Print first 10 for brevity\n",
    "        print(f\"Y coordinates: {y_coordinates[:10]}\")\n",
    "        print(f\"Z coordinates: {z_coordinates[:10]}\")\n",
    "        print(f\"red coordinates: {red_coordinates[:10]}\")\n",
    "        print(f\"Intensity values: {intensity[:10]}\")\n",
    "        print(f\"Classifications: {classifications[:10]}\")\n",
    "\n",
    "# Specify the path to your .las file\n",
    "file_path = '/data/sdd/training_v2.las'\n",
    "read_las_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3119ba4-02eb-4a30-be5c-dd09615c6d3a",
   "metadata": {},
   "source": [
    "So, first thing we need a func that can take this .las file and generate a pytorch state dictionary with it.\n",
    "\n",
    "Can set up a function to iterate over the requested number of points for testing purposes. If we need to we can extend this script with ground truth info, normal calculations, everything that Pointcept might require.\n",
    "\n",
    "May also need to look into putting this into the Pointcept package proper as part of the registry, which I'm still figuring out...\n",
    "\n",
    "## .las converter\n",
    "\n",
    "So now want some code to convert .las files into whatever format we want. Start with a basic function that can take an input file, and some naive number of points to convert, and outputs a .pth file in a format Pointcept should be able to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f501102d-7b71-4fbc-91cc-fca87ea044a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 points to output_file.pth\n"
     ]
    }
   ],
   "source": [
    "def las_to_pth(input_las_path, output_pth_path, num_points):\n",
    "    # Open the LAS file and read data\n",
    "    with laspy.open(input_las_path) as file:\n",
    "        las = file.read()\n",
    "\n",
    "        # Ensure num_points does not exceed the number of points in the file\n",
    "        max_points = min(num_points, len(las.points))\n",
    "\n",
    "        # Create the coord array (n x 3) for coordinates\n",
    "        coord = np.stack((las.x[:max_points], las.y[:max_points], las.z[:max_points]), axis=-1).astype(np.float32)\n",
    "\n",
    "        # Check if RGB data exists and create the color array (n x 3) for color data\n",
    "        if hasattr(las, 'red') and hasattr(las, 'green') and hasattr(las, 'blue'):\n",
    "            # Convert RGB from uint16 to float32 directly within np.stack\n",
    "            color = np.stack((las.red[:max_points], las.green[:max_points], las.blue[:max_points]), axis=-1).astype(np.float32)\n",
    "            # Normalize RGB values if necessary (typical range in LAS is 0 to 65535)\n",
    "            color /= 256.0  # Normalize to [0, 1] if you prefer to work with normalized colors\n",
    "        else:\n",
    "            color = np.zeros((max_points, 3), dtype=np.float32)  # Default to black if no color data available\n",
    "            print(\"RGB data not found in LAS file. Defaulting to black for color.\")\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        tensors = {\n",
    "            'coord': torch.tensor(coord, dtype=torch.float32),\n",
    "            'color': torch.tensor(color, dtype=torch.float32),\n",
    "            'scene_id': \"scene9999_00\",\n",
    "        }\n",
    "\n",
    "    # Save the dictionary as a PyTorch state dictionary (.pth file)\n",
    "    torch.save(tensors, output_pth_path)\n",
    "    print(f\"Saved {max_points} points to {output_pth_path}\")\n",
    "\n",
    "# Specify the input LAS file, output PTH file path, and number of points\n",
    "input_las_path = '/data/sdd/training_v2.las'\n",
    "output_pth_path = 'output_file.pth'\n",
    "num_points = 1000  # Number of points to process and save\n",
    "\n",
    "# Call the function\n",
    "las_to_pth(input_las_path, output_pth_path, num_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984bfc2-fd8e-42fc-a2d8-eeffaa5ff3c8",
   "metadata": {},
   "source": [
    "Now lets read the output and check it matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4c63f9-bf9d-49f5-96a8-b212397e340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([1000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [5.3873944e+05 1.7774992e+05 8.9729996e+00]\n",
      "        [5.3873975e+05 1.7774936e+05 8.9779997e+00]\n",
      "        [5.3873825e+05 1.7775225e+05 8.9689999e+00]\n",
      "        [5.387386e+05 1.777515e+05 8.987000e+00]\n",
      "        [5.3873894e+05 1.7775097e+05 8.9829998e+00]\n",
      "<class 'torch.Tensor'>\n",
      "color: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([1000, 3])\n",
      "    Dtype: torch.float32\n",
      "    First few elements:\n",
      "        [188. 197. 168.]\n",
      "        [181. 189. 165.]\n",
      "        [183. 192. 161.]\n",
      "        [180. 189. 158.]\n",
      "        [181. 193. 157.]\n",
      "<class 'torch.Tensor'>\n",
      "scene_id: <class 'str'> scene9999_00\n"
     ]
    }
   ],
   "source": [
    "# Load the contents of the .pth file\n",
    "data = torch.load(output_pth_path)\n",
    "\n",
    "# Call the function to print the structure\n",
    "print_structure(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae06315-93a6-4312-9f49-8ca5baa3a3c3",
   "metadata": {},
   "source": [
    "As I recall from looking at Pointcept's data readers, it can handle torch tensors so even if this doesn't look *exactly* like the Scannet data with it's numpy arrays, this should be *technically* fine as input to Pointcept assuming normals are optional.\n",
    "\n",
    "As for if the data has the necessary numerical characteristics to be processed properly, we note that the QH data for the x, y, z length scales are sometimes 5 orders of magnitude higher than those found in the Scannet data.\n",
    "\n",
    "Maybe we should get min-max for x, y, z for both the Scannet and QH datasets and compare them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdbd9468-e5b7-4d71-995b-b65cccd2d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X range: 538698.605 to 538742.333\n",
      "Y range: 177690.766 to 177752.815\n",
      "Z range: 6.697 to 29.134\n"
     ]
    }
   ],
   "source": [
    "def las_min_max_ranges(input_las_path):\n",
    "    # Open the LAS file and read data\n",
    "    with laspy.open(input_las_path) as file:\n",
    "        las = file.read()\n",
    "\n",
    "        # Calculate min and max for x, y, and z\n",
    "        x_min, x_max = las.x.min(), las.x.max()\n",
    "        y_min, y_max = las.y.min(), las.y.max()\n",
    "        z_min, z_max = las.z.min(), las.z.max()\n",
    "\n",
    "    print(f\"X range: {x_min} to {x_max}\")\n",
    "    print(f\"Y range: {y_min} to {y_max}\")\n",
    "    print(f\"Z range: {z_min} to {z_max}\")\n",
    "\n",
    "# Example usage:\n",
    "las_min_max_ranges('/data/sdd/training_v2.las')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5788daa4-9145-4afd-b229-c601f63ee189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X range: 0.56696617603302 to 4.752572059631348\n",
      "Y range: 0.31187281012535095 to 3.864165782928467\n",
      "Z range: -0.012044666334986687 to 2.501612901687622\n",
      "\n",
      "X range: 0.7937601804733276 to 10.793277740478516\n",
      "Y range: -0.05707528442144394 to 4.980363845825195\n",
      "Z range: 0.0002449717721901834 to 3.1450295448303223\n"
     ]
    }
   ],
   "source": [
    "def pth_min_max_ranges(input_pth_path):\n",
    "    # Load the state dictionary from a .pth file\n",
    "    data = torch.load(input_pth_path)\n",
    "\n",
    "    # Assuming 'coord' tensor is [n x 3] for x, y, z\n",
    "    coord = data['coord']\n",
    "\n",
    "    # Calculate min and max for x, y, and z\n",
    "    x_min, x_max = coord[:, 0].min().item(), coord[:, 0].max().item()\n",
    "    y_min, y_max = coord[:, 1].min().item(), coord[:, 1].max().item()\n",
    "    z_min, z_max = coord[:, 2].min().item(), coord[:, 2].max().item()\n",
    "\n",
    "    print(f\"X range: {x_min} to {x_max}\")\n",
    "    print(f\"Y range: {y_min} to {y_max}\")\n",
    "    print(f\"Z range: {z_min} to {z_max}\")\n",
    "\n",
    "# Example usage:\n",
    "pth_min_max_ranges('../data/scannet/test/scene0731_00.pth')\n",
    "print()\n",
    "pth_min_max_ranges('../data/scannet/test/scene0744_00.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b0a90-d480-4544-8dab-dd0e9877652a",
   "metadata": {},
   "source": [
    "Let's check all the scannet data min-max ranges at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fc620e0-f388-4660-9cbb-f1317d544b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X range across all files: -2.1278457641601562 to 17.116708755493164\n",
      "Total Y range across all files: -1.4605504274368286 to 18.189441680908203\n",
      "Total Z range across all files: -0.37873902916908264 to 6.966972827911377\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "def pth_min_max_ranges(directory):\n",
    "    # Recursively find all .pth files in the given directory\n",
    "    pth_files = glob.glob(os.path.join(directory, '**/*.pth'), recursive=True)\n",
    "\n",
    "    # Initialize min and max values to None initially\n",
    "    x_min, x_max = None, None\n",
    "    y_min, y_max = None, None\n",
    "    z_min, z_max = None, None\n",
    "\n",
    "    for file_path in pth_files:\n",
    "        # Load the state dictionary from a .pth file\n",
    "        data = torch.load(file_path)\n",
    "\n",
    "        # Assuming 'coord' tensor is [n x 3] for x, y, z\n",
    "        coord = data['coord']\n",
    "\n",
    "        # Calculate min and max for each file and update global min/max\n",
    "        if x_min is None:\n",
    "            # Initialize min/max values with the first file's values\n",
    "            x_min, x_max = coord[:, 0].min(), coord[:, 0].max()\n",
    "            y_min, y_max = coord[:, 1].min(), coord[:, 1].max()\n",
    "            z_min, z_max = coord[:, 2].min(), coord[:, 2].max()\n",
    "        else:\n",
    "            # Update min/max values based on this file's data\n",
    "            x_min = min(x_min, coord[:, 0].min())\n",
    "            x_max = max(x_max, coord[:, 0].max())\n",
    "            y_min = min(y_min, coord[:, 1].min())\n",
    "            y_max = max(y_max, coord[:, 1].max())\n",
    "            z_min = min(z_min, coord[:, 2].min())\n",
    "            z_max = max(z_max, coord[:, 2].max())\n",
    "\n",
    "    print(f\"Total X range across all files: {x_min.item()} to {x_max.item()}\")\n",
    "    print(f\"Total Y range across all files: {y_min.item()} to {y_max.item()}\")\n",
    "    print(f\"Total Z range across all files: {z_min.item()} to {z_max.item()}\")\n",
    "\n",
    "# Example usage:\n",
    "directory_path = '../data/scannet'\n",
    "pth_min_max_ranges(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3462d-43d5-4b37-8795-6f9042886c88",
   "metadata": {},
   "source": [
    "So, between minus a couple to just under 20 on Scannet. Let's check S3DIS too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48279306-58ae-4aea-99ea-89081b74ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total X range across all files: -37.928 to 29.927\n",
      "Total Y range across all files: -26.078 to 46.05599999999999\n",
      "Total Z range across all files: -2.6450000000000005 to 6.576\n"
     ]
    }
   ],
   "source": [
    "pth_min_max_ranges(\"../data/s3dis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961ab43-6c7a-4c11-9bb4-34c87b534c30",
   "metadata": {},
   "source": [
    "So, broadly similar for S3DIS, plus-minus O(10^2).\n",
    "\n",
    "I'm unsure how to treat the negative coords in these datasets... might not need to worry about them for now, maybe Pointcept is \"smart\" enough to just work with data with all positive coords. Seems the majority are positive anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19b639-14bc-407a-9a20-da2b5ff14b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pointcept)",
   "language": "python",
   "name": "pointcept"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
